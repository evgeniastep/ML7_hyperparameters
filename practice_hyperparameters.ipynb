{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/qmxhdvlx3kx97plxw0bx1vnw0000gn/T/ipykernel_30882/3200764734.py:23: MatplotlibDeprecationWarning:\n",
      "\n",
      "The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные моделиё\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамблиd\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import optuna\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем данные\n",
    "data = pd.read_csv('data/_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем матрицу наблюдений $X$ и вектор ответов $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на тренировочную и тестовую в соотношении 80/20. Для сохранения соотношений целевого признака используем параметр stratify (стратифицированное разбиение). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.75\n",
      "f1_score на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса логистическая регрессия\n",
    "log_reg = linear_model.LogisticRegression(max_iter = 1000)\n",
    "#Обучаем модель, минимизируя logloss\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(log_reg.score(X_test, y_test)))\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> **GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 915 ms, sys: 177 ms, total: 1.09 s\n",
      "Wall time: 8min 39s\n",
      "accuracy на тестовом наборе: 0.75\n",
      "f1_score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'C': 0.3, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.12,0.11, 0.3, 0.5, 0.7, 0.9]}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.12, 0.11, 0.3, 0.5, 0.7, 0.9]}\n",
    "]\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  #количество фолдов кросс-валидации\n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение точности при кросс-валидаци: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшее значение точности при кросс-валидаци: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAALFCAYAAAD3O39DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB77klEQVR4nOzdeVxUdf///yfIIAi4oCjua4Ebgopparll5ZKJ2mVumVpmIea+kQvkjpmh5pK7uaSW6aVdmUt66acIzcwuFTPLNBU1QlyQEWZ+f/hjvk6gIiMeJx/3bnO7Oe/zPuf9muEwzYvX+7yPi9VqtQoAAAAAACflanQAAAAAAAA4gsQWAAAAAODUSGwBAAAAAE6NxBYAAAAA4NRIbAEAAAAATo3EFgAAAADg1EhsAQAAAABOjcQWAAAAAODUSGwBAAAAAE7NzegAAGcxYsQIffbZZ3fsU69ePS1fvvwBRQQAcHYBAQEKDw9X//79jQ7lnqWlpWnVqlXatGmTfvvtN+XLl0+VKlVS586d1a5dO7m4uBgdIoBHCIktkENvvvmmOnfubHs+Z84cHT58WLNmzbK1eXt7GxEaAAAP1MWLF9WnTx+dPXtW3bt3V1BQkCwWi3bu3KkRI0Zo3759io6OJrkF8MCQ2AI5VK5cOZUrV8723NfXV+7u7goODjYuKAAADDB8+HCdO3dOa9asUYUKFWztTZo0UalSpfTee++padOmat68uXFBAnikcI0tkAf27dunbt26qVatWqpXr56GDx+upKQk2/ZPP/1UAQEB2T5iY2Nt/UaMGHHbfqdPn7b1++233xQREaGGDRsqODhY3bt31/79+23bT58+bbdvtWrV1KhRI02dOlUWi8XWLz4+Xr1791ZoaKhq1KihZs2aKTY21q7P2rVr9fzzz6tGjRp2xxwxYsRt34/Y2FgFBATYnm/evFmhoaGaPn26JCkjI0Pz589XmzZtFBQUpODgYHXu3Fnffvut3TGaNWumnTt36rnnnlOtWrX00ksvKS4uzm6MO72nR48eVXh4uOrXr6/q1aurcePGevfdd3X9+vU7/jxXrFih5s2bKyQkRN26ddOxY8fstq9du1ZhYWEKDg5WUFCQ2rVrpy+++OK2P+8aNWro2Wef1caNG2/7HknSf//73yzv7ZUrVxQdHa3GjRsrODhYHTp00Ndff23b3qxZsyw/i0GDBikgICDLexUSEiKz2WzXNyIiIsuYly9f1qRJk9SiRQvVrFlTbdq00bp16+z2s1qtWrJkiZ5//nkFBQXpmWee0cKFC2W1Wu/6s8k8Pz/99FPb8dLS0tS8efMs78mtbj2vb30vJWnnzp22bbfatm2bwsLCVLNmTTVs2FDvvvuurl27Znvv7vT7drdzUJLi4uLs3mtJ+vPPP1W3bl01a9Ys25+TxWLRgAEDVKNGDf3yyy85Pheys23bNnXp0kUhISGqUaOGnnvuOX388cd2fc6fP6/hw4erQYMGtnP6wIEDtu1ms1nvv/++mjdvrqCgILVp08buMozszrHMczzzcyk2NlbPPPOMZs2apXr16qlRo0a6dOmSrl+/runTp6tly5aqUaOGateurVdffVVHjhyxO96uXbvUuXNnBQcHq1GjRhozZoxSUlKUnJysmjVr6r333rPrn5qaqjp16ujDDz+87Xtzp8/JO30m3+49t1gsmjFjhpo1a2b7vJw+fbpu3Lhh65OT351MaWlpqlOnjqZMmWLXnp6ervr16+vdd9+1ta1du1atW7dWjRo11KRJE8XGxiojI8O2fcSIEXrllVc0duxY1a5dW61atbLbnunvPzdJ+vnnn1W9enV17979tu/lkSNHtGfPHvXu3dsuqc3Us2dPde3aVQUKFLjtMQDgfqNiC9xn8fHxevXVV1W/fn29//77unTpkmbOnKkePXpo3bp18vDwsPWdNWuW/Pz8bM//9a9/ZTmen5+f3XTnr7/+2u7L2/Hjx/XSSy+pQoUKioyMlMlk0rJly/TKK69o0aJFqlevnq1vv3791KRJE6Wmpmrv3r1asGCBKlasqE6dOuno0aPq2bOnnnvuOc2YMUNWq1WbNm3SrFmzVKlSJbVu3Vrx8fGKjIxUx44dFRkZKS8vL0lSeHh4jt+f69evKyoqSn369FHbtm0lSTExMVq1apUGDx6sgIAAJSYmavbs2RowYIC+/vpreXp6SpKSkpI0fPhwhYeHq1y5clq0aJF69+6ttWvXqlOnTmrcuLEkafz48ZKksWPHSpL8/f11/vx5de3aVcHBwZo8ebLc3d21e/duLV68WMWLF9frr7+ebbxbt25VdHS0+vbtq/r16ys2NlZvvPGG/vOf/8jd3V0ff/yx3n33XfXv31916tTRpUuXtGDBAg0ZMkQhISHy9/fP8vO+dOmSVq9ereHDh6tmzZqqWLFilnFv3LihiRMn2rVlZGSoV69eti/olSpV0meffaa33npLS5cuVd26dbMcZ9++fdq8eXO2r83FxUXffPONnn76aUnS1atXtWvXLrm6/r+/eV6/fl1dunTRn3/+qYiICJUuXVrbtm3T6NGjdfHiRb3xxhuSpKlTp2rp0qV69dVX1bBhQx06dEgxMTFKT0+/688mPT09S2wfffSR3ZftO/Hy8tKOHTv0wgsv2Nq2bNkiV1dXuz/KbNq0SUOGDFHbtm319ttv648//tCMGTN0/PhxLV68WLNmzZLZbNaFCxcUHh5u+32RpOLFi0u68zlYtWrVbOObPn26Ll++rIIFC2a7/T//+Y/i4uK0YMEClSlTJsv27M6F7Hz99dd666231KNHD/Xv31/Xr1/XypUrFRUVpRo1aqhWrVq6evWqXn75ZWVkZGjo0KEqUaKEFi1apF69eumzzz5ThQoVNGTIEO3atUv9+vVTrVq1tGvXLo0YMUImk0lt2rS5axyZzpw5o127dmnGjBlKTk5WoUKFFBERoX379mnQoEEqV66cTp48qZkzZ2rw4MHavHmzXFxctHPnTvXr10/NmzfX+++/r+TkZE2dOlV//PGHFi5cqBYtWmjTpk0aOHCgbZrrV199pWvXrunFF1/MNpa7fU42adJEa9askZT1MhNfX99sj7lgwQKtWrVKw4cPV9myZXXw4EHNmDFDJpNJEREROf7dyZQ/f349++yz+uKLLzRs2DDba9u7d6/++usvtWvXTpI0b948zZgxQ926ddPIkSN15MgRxcbG6uzZs3bnyb59+5Q/f37Nnj1b165dU758+XL0c5swYUK2v5O3+u9//ytJdn+s+ftrGTNmTI7GA4D7hcQWuM+mT5+uihUrat68ebYvErVq1VLr1q21fv16de3a1da3atWq2X6RvdXfpzufOHHCbvusWbPk7u6uZcuW2a7xbdKkidq0aaOpU6faVQfKlStnO1aDBg20du1a/fTTT7bE9sknn9S0adNsiU3Dhg21Y8cOxcXFqXXr1vrxxx8lSaNGjbIltZkx5tS///1vmUwm9enTx/b+nD9/XgMHDrSrEOTPn1/9+/dXQkKCLebU1FSNGzfO9uW1fv36atGihebPn68ZM2bYksjM9+HW923Pnj2qWrWqZs6cadv+5JNPau/evYqLi7ttYpuUlKQuXbpo0KBBkm5Ws/r27atffvlFVatW1alTp9S7d2+9+eabtn1Kly6tsLAw7d+/X61bt7a13/rzLlmypHbs2KEjR45km9guX75c165dU7FixWxtu3fv1sGDBzV79my1aNHC9h6cOnVK3377bZbE1mKx6N1331X16tX1v//9L8sYTz31lLZv325LbHfs2CE/Pz+7ZPDTTz/VsWPHtHr1aoWEhEiSGjdurPT0dM2ZM0edO3eWq6urli1bpm7dumno0KG29/bChQuKj49X37597/iz+XsCe/bsWS1YsOC2cWf3Ov773//KbDbL3d1daWlp2r59u0JDQ22VU6vVqpiYGDVu3FgxMTG2fStUqKCePXtq165dtiQ2M55bf18y3e0c/LtDhw7p888/V9WqVZWSkpJt/B9//LHCwsLUoEGDbLdndy5k5/jx42rfvr1Gjx5tawsJCdETTzyhuLg41apVS5999pn++OMPffbZZ7ZEvHbt2nrxxRcVHx8vs9msL7/8UqNGjdIrr7wi6eZnxR9//KG4uLh7SmzT09M1fPhw23lpNpt19epVRUZGqlWrVpJuLrh35coVTZ48WRcvXpSfn59iY2NVtWpVzZo1y5bcubu7a+bMmbp48aI6dOigLVu2KC4uTvXr15ckbdiwQU8++aRKliyZbSw5+ZzMTGBzepnJd999pxo1aqhDhw621+Lp6SkfHx9JOfvdKVy4sN0x27Vrp/Xr12v//v22923z5s2qVKmSatasqcuXL2vOnDn617/+pcjISElSo0aNVLhwYUVGRurVV1/VY489Znv/o6Ki7P64djdffvmlDh48mO1n0q3Onj0rSXf9/xcAPEhMRQbuo9TUVB08eFBPP/20rFar0tPTlZ6errJly6py5crau3fvfR/zu+++U9OmTe0WrnJzc1Pr1q31008/6erVq7Z2i8Wi9PR0Xb9+XZs2bdKlS5dUo0YNSdKLL76oBQsW6MaNGzp69Ki+/PJLffDBB8rIyLBNrQsKCpIkLVq0SOfPn5fZbL7rX/ZvlZiYqAULFqhLly521YPp06frlVdeUVJSkvbt26f169fbppbeOlXWzc3N7ou1h4eHnnrqKcXHx9917EaNGmnFihXKnz+/jh8/ru3bt+vDDz9UUlJSlum4t+rcubPGjh0ri8WiK1euaOvWrfLw8FDp0qUl3ZzyN2TIEKWkpOiHH37Q559/bpv6+ffjZr7/ly9f1ieffCI3NzcFBgZmGfPixYuaPXu2hg8frvz589va9+/fL5PJZFclcXV11erVq7Otmq9evVoXLlzQW2+9le1ra968uXbs2CGr1SrpZpUzM+HI9N1336l06dK2L+aZXnjhBaWlpengwYP64YcflJ6erpYtW9r1iYyM1EcffZTt2HcyZcoU1a1bV02bNs1R//r168tqtdqS2N27d8vb29su0T9x4oTOnTunZs2a2X4v09PTFRoaKm9v7xz/bt7LOWi1WvXuu++qY8eO2f6cMzIytHXrVh08eFAvv/xytuPd7lzITp8+fTR58mRdvXpVP/30k7Zs2aJ58+ZJ+n/n4v79+1WmTBm76rKnp6e+/PJLderUyTY19+8/y9jYWEVHR99x/OzcOo67u7sWLlyoVq1aKTExUd9++61Wr16tnTt32mK8fv26Dh8+rBYtWtgtOtSqVSt9+eWXKlasmJ588kmVKlVKn3/+uSTp3Llz+uabb9S+ffvbxnEvn5M59cQTT2jv3r3q0qWLPvroIx0/flzdunWzVVZz8rvzd/Xq1VOpUqVssyzS0tK0bds22zEPHDig69evZzmPMz8Tbj2PCxcufE9JbVpamqZMmaJ+/frZzSTKTubnd3bTmwHAKFRsgfsoJSVFFotFCxYs0IIFC7Jsv9sX09y4dOlStpWcYsWKyWq16sqVK7a20aNH21VzKleubJu+ef36dUVHR+vzzz9Xenq6ypQpo5CQELm5udkSn9DQUEVGRmr+/Pl206Nz6qmnnlL16tX12muv2bUfOnRI48eP16FDh+Tp6akqVaqoVKlSkmQbO/M1ubnZf2wVLVpUycnJdx3bYrHovffe08cff6xr166pZMmSCgoKyvHPZNmyZZo0aZKkm8lu5rTS33//XWPGjNE333wjk8mkSpUq2ZKYW2OXpGeeecbueVhYmCpVqpRlrOnTp6tatWpq1aqVXXUxOTlZhQsXtpsqfDvJycmaOXOmhg0bdtvVups0aaKRI0fq0KFDqlixovbs2aMBAwbo3//+t63PpUuXsv2Sm3nOpaSk2F7n7aZs3ovvvvtO27Zt08aNG287hfrv3N3d1bhxY23fvl2NGzfWli1b9Pzzz9slRpnnyPjx423ToW91/vz5HI11L+fghg0b9Ntvv2nu3LlZrpuUpI0bN2rjxo22qazZud25kJ2kpCSNHTtW27Ztk4uLi8qXL29L7jN/RsnJySpatOhtj5H5Ou7U517cOrNDujmFdeLEiTpx4oS8vLwUGBhouw7TarXq0qVLslqtdxzf1dVVYWFhWrx4scaOHavPP/9c3t7eWX6/bpWTz8m/x3o3ffr0kZeXl9avX6+YmBhNmzZNjz32mCIjI1W/fv0c/e78nYuLi9q2bau1a9cqMjJSO3fu1LVr12yXbWT+fG43w+TW8/heX8+CBQtkMpnUs2dP21Tj28n8w96ZM2dUpUqVbPskJiaqePHirIoM4IEhsQXuIy8vL7m4uKhnz552U1AzZV4rej8VKlRIFy9ezNJ+4cIFSVKRIkVsX3bCw8PVpEkTWSwWnThxQlFRUZo6dareeecdTZgwQV9++aXef/99Pfnkk7Yvm3+fHvnSSy9pz549Sk9P15gxY1SmTBn169cvR7HGxsZq7NixGjt2rO1asCtXrqhPnz4KCAiwTblzdXXVrl279OWXX9rtn13ycPHixRx9CZ8/f76WLFmi8ePHq2XLlrbpgh07dsxR7G3btlWtWrW0Z88ezZo1S0888YSee+45vf766zKZTFq3bp2qVq0qNzc3HT9+3FZNutWHH34oPz8/mc1m7d27V7Nnz1aTJk307LPP2vr8+OOP2rRpU7YLzPj4+Cg5OVlWq9Xuy+Lhw4dltVpVvXp1W9vMmTNVrlw5hYWF6bvvvsv2Nfn4+Cg0NFTbt29X+fLlVbZs2SyVxUKFCunkyZNZ9r31/Mqs2iclJdkl6mfOnNHvv/+uOnXqyGQyZRvDrTIyMvTuu++qR48e2Sb8d9K8eXPFxMRo6NCh2rlzp5YtW6Zdu3bZtmf+IWLYsGF2153f+jpzIqfn4NWrVzV9+nRFRESoSJEi2R7r6aefVkBAgN577z0FBgbqySeftNt+p3MhO0OGDNGJEye0ZMkShYSEyN3dXampqfrkk09sfXx8fLK9dvn7779XoUKFbO9TUlKSXbXvl19+UXJysurUqSMpa6UucwGuO/n999/11ltvqUWLFpo3b57Kli0rFxcXffzxx7ZEytvbWy4uLnaL7Uk3q4nffvutatWqpcKFCyssLEyzZ8/W7t279cUXX6hVq1Z3/CNVTj4n75Wrq6u6du2qrl276s8//9SuXbs0d+5c9e/fX3v37s3R70522rVrp3nz5ikuLk5btmxRaGioLZHM/PnExMRku2jT3aar307m9P8PPvggR5eWNGrUSNLNRb6yS2zT09PVrl071a5dW3PmzMlVTABwr5iKDNxH3t7eqlatmk6cOKGaNWvaHo899phiY2PtVkrNCYvFctcFP0JDQ7Vz5067ymxGRoY2b96smjVr2n1JKV26tGrWrKlatWqpffv2aty4sW3l4f379+uJJ55QixYtbEntTz/9pKSkJLtrLmfOnKmvv/5akydP1vPPP59ljDtp2bKlJk2apPXr12vLli2Sbk4RTU5OVo8ePVSlShVbNXL37t229yDT9evX7SoJ169f1+7du297beKt9u/frypVqqhDhw62pDYxMVHHjh2zG+PvJkyYoM8++0xFixZVSEiI+vfvr0KFCik+Pl5//fWXfv31V3Xs2FE1a9a0VfKyi12SHn/8cdWsWVN16tRRRESEChcubLfysyRFR0frpZdeynbqat26dXXjxg3b8aWbVa6RI0fappxK0rFjx7R27Vq98847d62WtGjRQtu3b892GrJ08/z6448/7FbNlW5WG00mk4KCghQUFCSTyWSbUppp0aJFGjRoUI4Xrfnkk0+UlJRkd71yTjVp0kR//vmnZs2apaJFi9qmzWeqVKmSihYtqtOnT9v9bpYoUULTp0/X4cOHczROTs/BDz/8UEWLFrW79/Xf+fr6avDgwWrWrJmGDRumy5cv222/07mQnf3796tly5Z64oknbL+Tfz8X69atq1OnTunnn3+27ZeWlqb+/ftr3bp1tsR1x44ddseOiYnRhAkTJN38nDt37lyWse/mp59+Ulpaml5//XWVK1fOdm5mvp9Wq1VeXl6qWrVqlnNp9+7dev31121/pCtdurQaNGigZcuW6ciRIwoLC7vj2PfyOZlTnTt3tq1UXLRoUYWFhalr165KSUnRlStXcvS7k53KlSurevXq2rx5s3bt2mW3KFqtWrVkMpmUmJhodx67ubnpvffey/GCa383depU1a9f33a9/d089thjeuqpp7RgwQKdOnUqy/Z58+bpr7/+sosdAPIaFVvgPhs0aJBef/11DR48WC+88IIyMjK0aNEiHTx4MMdf2K9cuaKEhAQdPXrUloTdTnh4uHbv3q0ePXrYqocrVqzQqVOnslzf+Pvvv9uuh8xccCjzC3lQUJC++OILrVq1SpUrV9bRo0f14YcfysXFRampqZJuLk6zdOlSPfvsszn+AvR3mRXKSZMm6amnnlLFihXl7e2tuXPnys3NTW5ubvryyy9tVarMsTONHDlSb7/9tooWLaqFCxfq2rVrOaoYBwUFac6cOZo/f76Cg4N18uRJzZs3T2azOcsYt0pJSdG4ceN06dIlBQYGatu2bbp06ZLq1q2rokWLqnTp0vr444/l7++vggUL6r///a+WLVuWbexHjhzRxYsXlZaWpn379ik5OTlLtSO7n9ut711ISIhGjBiht99+W2XLltXnn3+uX375xe76x//973/q0KHDbb8436p58+aKjo7WiRMnNGrUqCzbw8LCtHLlSr311luKiIhQmTJltGPHDq1fv17h4eG2ClKPHj20ZMkSubu7q169ejp48KBWrVqlYcOG5WjqtHSzQjllypTbTp2+k4IFCyo0NFRLly5V7969s2zPly+fBg4cqDFjxihfvnxq2rSpUlJSNGfOHCUmJtpVu+8mJ+fgjz/+qBUrVuQoqR89erSef/55vf/++3rnnXds7Xc6F7ITFBSkTZs2qXr16vL399f333+v+fPn2/0Oh4WFafny5erXr5+tmrxs2TLduHFDXbp0UdmyZfXcc89p2rRpun79uqpWrardu3dr586dtssPmjZtqnnz5mnevHmqVauWduzYkeUPNNmpXr263NzcNG3aNPXq1Utms1mffvqp7XZVmVXfiIgI9evXT4MGDdKLL76oixcv6r333lOLFi30+OOP247XsWNHDRo0SJUrV1atWrXuOPa9fE7mVGhoqBYtWqRixYopJCREiYmJWrx4serVqydfX98c/+5kp127dpoyZYrc3Nz03HPP2dqLFCmiPn36aObMmbpy5YqeeOIJJSYmaubMmXJxccnxH0H+7siRIzme+p9p/PjxeuWVV/TSSy+pR48etlW3//Of/2jz5s3q3LmzXewAkNdIbIH7rFGjRlq4cKFmzZqliIgImUwmVa9eXYsXL77rKpuZEhIS1LVrV/n6+mrcuHF37PvYY49p5cqVeu+99zRy5Ei5uLgoKChIy5Yty7JK7ocffmi7VVCRIkVUv3592zW3I0aM0I0bN/T+++/LbDbbphgfP35cO3bsUEZGhsaPHy93d/dsE6B7MWrUKD3//POKjY3VyJEjNWfOHE2dOlUDBgywVWxWrFih1157Tfv27bNbLGncuHGaOHGikpKSVLt2ba1atUrly5e/65h9+/bVX3/9pWXLlmn27NkqWbKk2rVrJxcXF82bN08pKSnZftEcN26cvL29tWjRIiUnJ6tkyZKKjIy0TTWfM2eOJkyYoBEjRsjd3V1VqlTRhx9+qIkTJ2rfvn12Kz1nLvCUL18++fn5qVevXlkqem+//fZtp8Xmy5dPCxYsUExMjGbOnKnU1FQFBARo0aJFdkmsj4+PBg8efNf3RLp5u51q1arJYrFkO/3X09NTy5cv1/Tp021fpitVqqQJEybYTeMeOnSoihYtqtWrV+ujjz5SmTJl9M4779yxYvl3ISEhtkVycqNFixb65ptvsr0MQJI6deokLy8vffTRR1qzZo0KFCig2rVrKyYm5rbXuGYnJ+dg69atFRoamqPjlShRQgMGDNCUKVNsK+xKdz4XsjN58mRFR0fb/shRoUIFjR8/Xhs3btS+ffsk3ay2rlixQlOnTlV0dLQsFouCg4O1bNky23swbdo0zZo1S0uXLtVff/2lypUr64MPPrCtxN23b18lJSVp4cKFunHjhpo0aaIJEybc9Q9M5cuX1/Tp0zVr1iz169dPhQoVUnBwsJYvX67u3btr3759CggIUNOmTTV37lzNmjVLb731lnx9fdW2bVv179/f7nhPP/20XFxc7lqtle7tczKnBgwYIHd3d61fv16zZ8+Wj4+PmjVrZvvdy+nvTnYyV2tu2rRplj9uvv322/Lz89PKlSv10UcfqVChQmrQoIEGDRp01z+E3s6rr76ao8/RW5UqVUpr1qzR0qVL9e9//1vz58+Xu7u7KlWqpOnTp2c7AwQA8pKL9e+rmwDAQyg2NlazZs1SQkKC0aHgEcU5+HDZsmWLhg0bpl27dt23xa4AAM6Lii0AAHAa27Zt06FDh7R69WqFhYWR1AIAJLF4FAAAcCKnT5/W0qVLVaNGDQ0dOtTocAAADwmmIgMAAAAAnBoVWwAAAACAUyOxBQAAAAA4NRJbAAAAAIBTI7EFAAAAADi1R/p2P6GlnjI6BCDP7exc2OgQgDyXnnjF6BCAPGd6rITRIQB5zmvcKqNDyJUbF08YNrapWCXDxn6YULEFAAAAADg1ElsAAAAAgFN7pKciAwAAAIDDLBlGR/DIo2ILAAAAAHBqVGwBAAAAwBFWi9ERPPKo2AIAAAAAnBoVWwAAAABwhIWKrdGo2AIAAAAAnBqJLQAAAADAqTEVGQAAAAAcYGXxKMNRsQUAAAAAODUqtgAAAADgCBaPMhwVWwAAAACAUyOxBQAAAAA4NaYiAwAAAIAjWDzKcFRsAQAAAABOjYotAAAAADjCkmF0BI88KrYAAAAAAKdGxRYAAAAAHME1toajYgsAAAAAcGoktgAAAAAAp8ZUZAAAAABwhIWpyEajYgsAAAAAcGpUbAEAAADAAVYWjzIcFVsAAAAAgFMjsQUAAAAAODWmIgMAAACAI1g8ynBUbAEAAAAATo2KLQAAAAA4gsWjDEfFFgAAAADg1KjYAgAAAIAjLBlGR/DIo2ILAAAAAHBqJLYAAAAAAKdm2FTkatWqyWq15qjvkSNH8jgaAAAAAMglFo8ynGGJ7fLly/Xmm2+qTJky6tatm1FhAAAAAACcnGGJbZ06dTRnzhy98sorKlOmjEJDQ40KBQAAAAByz0LF1miGXmNbp04dde3aVVOmTDEyDAAAAACAJIvFog8++ECNGzdWcHCwXnvtNZ06dSrbvrGxsQoICMj2MXLkSFu/X3/9Va+//rpCQkLUsGFDRUVFKTU1NVdj3o7hi0cNGzZMixcvNjoMAAAAAHjkzZkzRytXrlR0dLRWr14ti8WiPn36yGw2Z+nbq1cv7dmzx+7Ru3dvFShQQD179pQk/fXXX+rWrZvc3Ny0du1aTZs2TV999ZVdcfNexrwdwxPbfPnyycfHx+gwAAAAACB3rBbjHveR2WzWokWLFBERoSZNmigwMFAzZszQuXPntHXr1iz9vby85OfnZ3tcuHBBy5Yt05gxYxQQECBJWrFihdzc3DRjxgxVqVJFTz75pCIiIvTjjz/KarXe85i3Y9g1tpnOnz+v/fv369y5c0pLS5Onp6dKlCih2rVrq3jx4kaHBwAAAACPhKNHj+rq1atq0KCBra1gwYKqVq2a4uPj1aZNmzvuHxUVpbp166p9+/a2tj179uiZZ55R/vz5bW2dOnVSp06d7suYmQxLbK9fv67x48drw4YNcnFxUeHChZU/f36lpaUpOTlZLi4uevHFFzV27Fi5u7sbFSYAAAAA3Nk/ZPGoc+fOSZJKlixp1168eHHbttvZuXOnDhw4oA0bNti1//rrr2revLkmTZqkL7/8UiaTSc8884wGDBig/PnzOzTmrQxLbKdOnaq4uDh99NFHqlevnkwmk23bjRs3FBcXp7Fjx2rKlCl65513jAoTAAAAAB5azZs3v+P27du35/hYmQs6/b2wmD9/fl26dOmO+y5evFhNmzZV1apV7dqvXLmiBQsWqHXr1po1a5bOnDmj6OhoXbhwQdOmTXNozFsZdo3t5s2bNWnSJDVs2NAuqZUkk8mkRo0aacKECfriiy8MihAAAAAA7s5qzTDscT95eHhIUpZFmzIvGb2dM2fOKC4uTi+//HKWbW5ubqpYsaLGjRunGjVqqGXLlho1apQ2btyoP//8M9djZhknxz3vM6vVqkKFCt2xj5eXl65fv/6AIgIAAAAA53IvFdm7yZwOfP78eZUrV87Wfv78edtiUNnZtm2bfH191bBhwyzb/P399dhjj9m1ZT7/448/cj3m3xlWsW3cuLHGjBmjX3/9Ndvtp06d0vjx4/XUU0894MgAAAAA4NETGBgob29vxcXF2dpSUlJ0+PBhhYaG3na/ffv2qV69enJzy1o3DQ0Nta2AnOnYsWPKly+fypQpk+sx/86wiu0777yj/v37q1WrVvLz81PJkiXl7u4us9ms8+fP69y5cwoJCdGYMWOMChEAAAAA7u4+33bHKO7u7urWrZtiYmLk6+ur0qVLa9q0afL391fLli2VkZGhpKQk+fj42KYQS9Lhw4fVoUOHbI/Zu3dvhYWFaezYsXr11Vd1+vRpTZkyRe3atZOvr68k3XHMnDIssS1cuLCWL1+uAwcO2G73c/36dXl4eMjf31+hoaGqVauWUeEBAAAAwCMnIiJC6enpioyM1PXr1xUaGqqFCxfKZDLp9OnTthWOw8LCbPtcuHBBhQsXzvZ4lSpV0rJlyzR16lS1a9dOPj4+euGFFzRw4MAcjZlTLtZba8KPmNBSTHPGP9/OzoWNDgHIc+mJV4wOAchzpsdKGB0CkOe8xq0yOoRcuf79RsPG9qj9gmFjP0wMu8Y2J9LS0rLcBwkAAAAAgFs91Int5cuXNWLECKPDAAAAAAA8xAy7xjYnfH197+vy1QAAAABw3/1DFo9yZoYmtunp6dq6davi4+N19uxZmc1meXp6qkSJEgoNDVXLli1VunRpI0MEAAAAADzkDEtsT58+rd69eysxMVHVqlVT8eLFVahQIaWlpeno0aP69NNPFRsbq48++kilSpUyKkwAAAAAuDNLhtERPPIMS2yjoqJUpkwZrVu3Tj4+Plm2p6SkaODAgYqKitLcuXMNiBAAAAAA4AwMWzwqPj5ew4YNyzaplaSCBQtq6NChio+Pf8CRAQAAAACciWGJrY+PjxITE+/Y58yZM/Lw8HhAEQEAAABALlgtxj0gycDEtmPHjhoxYoTWrFmjkydPymw2S5LMZrNOnTql9evXa/To0QoLCzMqRAAAAACAEzDsGtv+/fvL1dVVU6dO1bVr17Js9/LyUteuXTVgwAADogMAAACAHLJQOTWaYYmti4uLwsPD1bdvXx05ckSJiYlKTU2Vh4eH/P39FRgYKHd3d6PCAwAAAAA4CUPvYytJJpNJQUFBRocBAAAAALnDta6GM+waWwAAAAAA7gcSWwAAAACAUzN8KjIAAAAAODUWjzIcFVsAAAAAgFOjYgsAAAAAjqBiazgqtgAAAAAAp0ZiCwAAAABwakxFBgAAAAAHWK0ZRofwyKNiCwAAAABwalRsAQAAAMARLB5lOCq2AAAAAACnRsUWAAAAABxhpWJrNCq2AAAAAACnRmILAAAAAHBqTEUGAAAAAEeweJThqNgCAAAAAJwaFVsAAAAAcASLRxmOii0AAAAAwKmR2AIAAAAAnBpTkQEAAADAESweZTgqtgAAAAAAp0bFFgAAAAAcweJRhqNiCwAAAABwalRsAQAAAMARXGNrOCq2AAAAAACnRmILAAAAAHBqTEUGAAAAAEcwFdlwj3Ria7akGx0CkOfyD51idAhAnksf9KbRIQB5zu1frxsdAgA8tB7pxBYAAAAAHMbtfgzHNbYAAAAAAKdGYgsAAAAAcGpMRQYAAAAAR7B4lOGo2AIAAAAAnBoVWwAAAABwBItHGY6KLQAAAADAqVGxBQAAAABHcI2t4ajYAgAAAACcGoktAAAAAMCpMRUZAAAAABzB4lGGo2ILAAAAAHBqVGwBAAAAwBEsHmU4KrYAAAAAAKdGYgsAAAAAcGpMRQYAAAAARzAV2XBUbAEAAAAATo2KLQAAAAA4wmo1OoJHHhVbAAAAAIBTo2ILAAAAAI7gGlvDUbEFAAAAADg1ElsAAAAAgFNjKjIAAAAAOIKpyIajYgsAAAAAcGpUbAEAAADAEVYqtkajYgsAAAAAcGoktgAAAAAAp8ZUZAAAAABwBItHGY6KLQAAAADAqVGxBQAAAABHWK1GR/DIo2ILAAAAAHBqVGwBAAAAwBFcY2s4KrYAAAAAAKdGYgsAAAAAcGqGTUVu1qyZXFxcctR3+/bteRwNAAAAAOTSP2gqssVi0axZs7R27VpdvnxZoaGhGjNmjMqWLZulb2xsrGbNmpXtccLCwjRp0iRJ0quvvqr/+7//s9ter149LV++XJK0f/9+denSJcsxli1bpieeeCJHcRuW2A4aNEijR49WpUqV1Lx5c6PCAAAAAAD8/+bMmaOVK1dq8uTJ8vf317Rp09SnTx9t2rRJ7u7udn179eqlzp0727UtXrxYq1atUs+ePW1tCQkJGjdunFq0aGFrM5lMdtvLlSunlStX2h2rUKFCOY7bsMS2TZs28vDw0MCBAzVp0iQFBgYaFQoAAAAA5J71n1GxNZvNWrRokYYMGaImTZpIkmbMmKHGjRtr69atatOmjV1/Ly8veXl52Z4fPnxYy5YtU3R0tAICAiRJf/75p/7880/VqlVLfn5+2Y577NgxValS5bbbc8LQa2xbtGih1q1ba8qUKUaGAQAAAACPvKNHj+rq1atq0KCBra1gwYKqVq2a4uPj77p/VFSU6tatq/bt29vaEhIS5OLioooVK952v4SEBFWuXNmh2A2/3U9kZKROnz5tdBgAAAAA4HTudlnnvaxXdO7cOUlSyZIl7dqLFy9u23Y7O3fu1IEDB7Rhwwa79mPHjsnHx0dRUVHau3evChQooOeee05vvvmmbWrzzz//rCJFiigsLEyJiYl6/PHHNXDgQAUFBeU4dsNXRfb29mYaMgAAAACnZbVYDXvcT6mpqZKU5Vra/PnzKy0t7Y77Ll68WE2bNlXVqlXt2o8dO6a0tDQFBQXpo48+Ur9+/bR27VpFRkZKks6ePavLly/r2rVrioyM1Jw5c1SsWDF169ZNx48fz3HshldsAQAAAAC5cz/vIOPh4SHp5rW2mf+WpLS0NHl6et52vzNnziguLk7z58/Psi0qKkrDhw+3LQT1+OOPy2QyaeDAgRo2bJhKliyp+Ph4eXp62haUqlmzpg4fPqzly5dr/PjxOYrdsMT2dstCZyc8PDwPIwEAAAAAB/xDbveTOQX5/PnzKleunK39/PnztsWgsrNt2zb5+vqqYcOGWba5ubllWd34sccek3Rz6nOxYsVUsGBBu+2urq6qXLmyEhMTcxy7YYntDz/8oL1796pgwYJ2K2n9nYuLC4ktAAAAAOSxwMBAeXt7Ky4uzpbYpqSk6PDhw+rWrdtt99u3b5/q1asnN7es6WX37t1VpkwZ2z1tJenQoUMymUyqUKGCdu/erQEDBmjjxo22e+Wmp6fr6NGjatmyZY5jNyyxXbBggUaOHKnvv/9eGzZsUIECBYwKBQAAAAAeee7u7urWrZtiYmLk6+ur0qVLa9q0afL391fLli2VkZGhpKQk+fj42E1VPnz4sDp06JDtMZ999llNnDhRQUFBatSokQ4dOqSpU6eqd+/e8vb2Vu3atVWkSBENHz5co0aNkslk0vz585WcnGx3L9y7MWzxKBcXF0VFRSl//vyaM2eOUWEAAAAAgGOsFuMe91lERIQ6duyoyMhIvfzyy8qXL58WLlwok8mks2fPqlGjRtqyZYvdPhcuXFDhwoWzPV63bt00evRoLV++XK1atVJMTIx69uypAQMGSLq5mPCSJUtUrFgx9e7dW//617+UnJysFStWqFixYjmO28Vqtd7fpbTu0YEDB7Rr1y69/fbbD3zsWv5PPvAxgQdt34GFRocA5Lmrg940OgQgz3mOGWN0CECey1+1qdEh5Mq1D/sbNnaBfrGGjf0wMXxV5JCQEIWEhBgdBgAAAADkzn2+7Q7uneH3sQUAAAAAwBEPdWKblpamDRs2GB0GAAAAANyexWLcA5Ie8sT28uXLGjFihNFhAAAAAAAeYg91Yuvr66vt27cbHQYAAAAA4CFm6OJR6enp2rp1q+Lj43X27FmZzWZ5enqqRIkSCg0NVcuWLVW6dGkjQwQAAACAO2NKsOEMq9iePn1arVu31qhRo5SQkCAPDw/5+fnJZDLp6NGjGjlypNq2baszZ84YFSIAAAAAwAkYVrGNiopSmTJltG7dOvn4+GTZnpKSooEDByoqKkpz5841IEIAAAAAyAErt/sxmmEV2/j4eA0bNizbpFaSChYsqKFDhyo+Pv4BRwYAAAAAcCaGJbY+Pj5KTEy8Y58zZ87Iw8PjAUUEAAAAAHBGhk1F7tixo0aMGKEBAwaofv36KlmypNzd3WU2m5WYmKjvvvtOMTEx6tixo1EhAgAAAMDdsXiU4QxLbPv37y9XV1dNnTpV165dy7Ldy8tLXbt21YABAwyIDgAAAADgLAxLbF1cXBQeHq6+ffvqyJEjSkxMVGpqqjw8POTv76/AwEC5u7sbFR4AAAAA5IyFxaOMZuh9bCXJZDIpKCjI6DAAAAAAAE7K8MQWAAAAAJyalWtsjWbYqsgAAAAAANwPJLYAAAAAAKfGVGQAAAAAcASLRxmOii0AAAAAwKlRsQUAAAAAB1gtLB5lNCq2AAAAAACnRmILAAAAAHBqTEUGAAAAAEeweJThqNgCAAAAAJwaFVsAAAAAcISVxaOMRsUWAAAAAODUqNgCAAAAgCO4xtZwVGwBAAAAAE6NxBYAAAAA4NSYigwAAAAAjrCweJTRqNgCAAAAAJwaFVsAAAAAcASLRxmOii0AAAAAwKmR2AIAAAAAnBpTkQEAAADAEVYWjzIaFVsAAAAAgFOjYgsAAAAAjmDxKMNRsQUAAAAAODUqtgAAAADgAKuFa2yNRsUWAAAAAODUSGwBAAAAAE6NqcjAP50pv9ERAHmPGWB4BLj6ljI6BAC3w+JRhqNiCwAAAABwalRsAQAAAMARVGwNR8UWAAAAAODUSGwBAAAAAE6NqcgAAAAA4AgrqxgajYotAAAAAMCpUbEFAAAAAEeweJThqNgCAAAAAJwaFVsAAAAAcICViq3hqNgCAAAAAJwaiS0AAAAAwKkxFRkAAAAAHMFUZMNRsQUAAAAAODUqtgAAAADgCIvF6AgeeVRsAQAAAABOjcQWAAAAAODUmIoMAAAAAI5g8SjDUbEFAAAAADg1KrYAAAAA4AgqtoajYgsAAAAAcGpUbAEAAADAAVYrFVujUbEFAAAAADg1ElsAAAAAgFNjKjIAAAAAOILFowxHxRYAAAAA4NSo2AIAAACAI6jYGo6KLQAAAADAqZHYAgAAAACcGlORAQAAAMABVqYiG46KLQAAAADAqVGxBQAAAABHULE1nKEV288//1zdu3fXCy+8oJiYGF25csVue1JSkpo3b25QdAAAAADwaLFYLPrggw/UuHFjBQcH67XXXtOpU6ey7RsbG6uAgIBsHyNHjrT1e/XVV7Ns7969u217Wlqaxo8frwYNGigkJESDBw9WUlLSPcVtWGK7du1ajR49WuXKlVOtWrX08ccfq0OHDjpz5oytj8VisXsOAAAAAMg7c+bM0cqVKxUdHa3Vq1fLYrGoT58+MpvNWfr26tVLe/bssXv07t1bBQoUUM+ePW39EhISNG7cOLt+sbGxtu2Z22JjY7V06VKdOHFCERER9xS3YYntsmXLNGbMGE2YMEHR0dHavHmz3Nzc1L17d124cMGosAAAAADg3lgMfNxHZrNZixYtUkREhJo0aaLAwEDNmDFD586d09atW7P09/Lykp+fn+1x4cIFW54XEBAgSfrzzz/1559/qlatWnZ9CxcuLElKTEzUhg0bFBkZqbp16yooKEjvvfee4uPjdeDAgRzHblhie/r0aTVo0MD2vFSpUlq6dKlcXFzUp0+fLNOSAQAAAAB55+jRo7p69apdnlawYEFVq1ZN8fHxd90/KipKdevWVfv27W1tCQkJcnFxUcWKFbPdZ//+/ZKk+vXr29oqVqyoEiVK5GjMTIYtHlW8eHH973//U9myZW1txYoV0/z58/Xyyy+rX79+mjRpklHhAQAAAECOGHm7n7utSbR9+/YcH+vcuXOSpJIlS9q1Fy9e3Lbtdnbu3KkDBw5ow4YNdu3Hjh2Tj4+PoqKitHfvXhUoUEDPPfec3nzzTbm7uysxMVFFihRR/vz573nMWxlWse3UqZPGjh2r+fPnKzEx0dZeqVIlzZkzR//73//Uq1cvo8IDAAAAgEdKamqqJMnd3d2uPX/+/EpLS7vjvosXL1bTpk1VtWpVu/Zjx44pLS1NQUFB+uijj9SvXz+tXbtWkZGRtjH/Pl5Ox7yVYRXb3r1768aNG/r4448VFBSkEiVK2LbVqVNHS5Ys0ZAhQ4wKDwAAAAByxsCK7fbtO+7bsTw8PCTdvNY289/SzVWLPT09b7vfmTNnFBcXp/nz52fZFhUVpeHDh6tQoUKSpMcff1wmk0kDBw7UsGHD5OHhke3CVHcb8+8MS2xdXFzUr18/9evXT1Zr1hMhKChIX3zxhX788UcDogMAAACAR0vmFOTz58+rXLlytvbz58/bFoPKzrZt2+Tr66uGDRtm2ebm5mZLajM99thjkm5Offb391dycrLMZrNd5fb8+fN2xc+7MfQ+tplcXFyybc+XL59CQkIecDQAAAAA8OgJDAyUt7e34uLibG0pKSk6fPiwQkNDb7vfvn37VK9ePbm5Za2bdu/e3e6etpJ06NAhmUwmVahQQXXq1JHFYrEtIiVJv/76qxITE+845t89FIktAAAAADitf8jtftzd3dWtWzfFxMRo+/btOnr0qAYOHCh/f3+1bNlSGRkZunDhgq5fv2633+HDhxUYGJjtMZ999ll9/vnnWrVqlU6dOqUtW7Zo6tSp6t27t7y9vVWiRAm1bt1akZGRiouL048//qhBgwapXr16Cg4OznHshk1FnjVrVo77hoeH52EkAAAAAABJioiIUHp6uiIjI3X9+nWFhoZq4cKFMplMOn36tJo3b65JkyYpLCzMts+FCxds96X9u27dusnFxUXLly/XxIkT5efnp549e+r111+39YmOjtbEiRNted9TTz1lW1wqp1ys2V3g+gD06dNHe/fuVcGCBeXl5XXbfi4uLve0RPW9qOX/ZJ4cF3iY7PtphdEhAHnu6lu9jQ4ByHNeH8w1OgQgz5lK3P46zofZX52aGDZ2kbVfGzb2w8Swiu2CBQs0cuRIff/999qwYYMKFChgVCgAAAAAACdm2DW2Li4uioqKUv78+TVnzhyjwgAAAAAAODlDF49yd3dXVFRUtqtnAQAAAIBT+IcsHuXMDM8oQ0JCuKUPAAAAACDXDE9sAQAAAMCZWS2GrMeLWzzU97FNS0vThg0bjA4DAAAAAPAQe6gT28uXL2vEiBFGhwEAAAAAt8c1toZ7qBNbX1/fPLuHLQAAAADgn8HQa2zT09O1detWxcfH6+zZszKbzfL09FSJEiUUGhqqli1bqnTp0kaGCAAAAAB4yBlWsT19+rRat26tUaNGKSEhQR4eHvLz85PJZNLRo0c1cuRItW3bVmfOnDEqRAAAAAC4K6vFuAduMqxiGxUVpTJlymjdunXy8fHJsj0lJUUDBw5UVFSU5s6da0CEAAAAAABnYFhiGx8fr9WrV2eb1EpSwYIFNXToUHXt2vUBRwYAAAAA94DKqeEMm4rs4+OjxMTEO/Y5c+aMPDw8HlBEAAAAAABnZFhi27FjR40YMUJr1qzRyZMnZTabJUlms1mnTp3S+vXrNXr0aIWFhRkVIgAAAADACRg2Fbl///5ydXXV1KlTde3atSzbvby81LVrVw0YMMCA6AAAAAAgZ1jEyXiGJbYuLi4KDw9X3759deTIESUmJio1NVUeHh7y9/dXYGCg3N3djQoPAAAAAOAkDL2PrSSZTCYFBQUZHQYAAAAA5A4VW8MZdo0tAAAAAAD3g+EVWwAAAABwZlxjazwqtgAAAAAAp0ZiCwAAAABwakxFBgAAAAAHMBXZeFRsAQAAAABOjYotAAAAADiAiq3xqNgCAAAAAJwaiS0AAAAAwKkxFRkAAAAAHGF1MTqCRx4VWwAAAACAU6NiCwAAAAAOYPEo41GxBQAAAAA4NSq2AAAAAOAAq4VrbI1GxRYAAAAA4NRIbAEAAAAATo2pyAAAAADgABaPMh4VWwAAAACAU6NiCwAAAAAOsFpZPMpoVGwBAAAAAE6NxBYAAAAA4NSYigwAAAAADmDxKONRsQUAAAAAODUqtgAAAADgAKuFxaOMRsUWAAAAAODUqNgCAAAAgAOsVqMjABVbAAAAAIBTe6Qrtr+knDU6BCDPZfx6wOgQgDx38ZC70SEAec7j9BGjQwDynKlEgNEhwEk90oktAAAAADiKxaOMx1RkAAAAAIBTo2ILAAAAAA6gYms8KrYAAAAAAKdGYgsAAAAAcGpMRQYAAAAAB3AfW+NRsQUAAAAAODUqtgAAAADgABaPMh4VWwAAAACAU6NiCwAAAAAOsFqp2BqNii0AAAAAwKmR2AIAAAAAnBpTkQEAAADAAVaL0RHgniq26enpWrFihb766iu79oyMDLVv315LliyRxcJPFQAAAADw4OQ4sb1x44befPNNTZgwQQcOHLDblpSUJIvFosmTJys8PFwZGRn3PVAAAAAAeBhZrC6GPXBTjhPbNWvW6Ntvv1VMTIyGDRtmt83Pz0+ff/65Jk+erN27d2v9+vX3PVAAAAAAALKT48T2008/Vc+ePdW6devb9nnxxRfVqVMnrV279r4EBwAAAADA3eQ4sT158qTq169/135PP/20fvvtN0diAgAAAACnYbW6GPbATTlObN3c3HTjxo0c9XNx4Q0GAAAAADwYOU5sH3vsMcXFxd2133fffacyZco4FBQAAAAAOAurxcWwB27KcWLbrl07rVq1Sj/++ONt+/zvf//Txx9/rOeff/6+BAcAAAAAwN245bRjx44d9e9//1vdu3dXx44d1aRJE5UpU0YWi0V//PGHdu/erU8++UQBAQHq3r17XsYMAAAAAIBNjhNbFxcXzZs3TxMnTtSaNWu0cuVK2zar1So3Nzd16tRJgwYNkoeHR54ECwAAAAAPG6vV6AiQ48RWkjw8PBQVFaW3335b3377rc6ePat8+fKpdOnSql+/vnx8fPIqTgAAAAAAsnVPiW0mX19ftWrV6q79LBaLevbsqaioKFWoUCE3QwEAAADAQ41FnIyX48WjcsNqteq7777T1atX83IYAAAAAMAjLFcVWwAAAADATRYrFVuj5WnFFgAAAACAvEZiCwAAAACQdHOdpA8++ECNGzdWcHCwXnvtNZ06dSrbvrGxsQoICMj2MXLkyCz9rVarevfuneX2sPv378/2GHFxcTmOm6nIAAAAAOAA6z9oKvKcOXO0cuVKTZ48Wf7+/po2bZr69OmjTZs2yd3d3a5vr1691LlzZ7u2xYsXa9WqVerZs2eWYy9dulR79uxRvXr17NoTEhJUrlw5u1vKSlKhQoVyHDeJLQAAAABAZrNZixYt0pAhQ9SkSRNJ0owZM9S4cWNt3bpVbdq0sevv5eUlLy8v2/PDhw9r2bJlio6OVkBAgF3fhIQEzZ49W8HBwVnGPXbsmKpUqSI/P79cx85UZAAAAABwgNVq3ON+Onr0qK5evaoGDRrY2goWLKhq1aopPj7+rvtHRUWpbt26at++vV17WlqahgwZooiICFWsWDHLfgkJCapcubJDsVOxBQAAAAAn1bx58ztu3759e46Pde7cOUlSyZIl7dqLFy9u23Y7O3fu1IEDB7Rhw4Ys26ZNm6bixYurW7du2V57+/PPP6tIkSIKCwtTYmKiHn/8cQ0cOFBBQUE5jj1PK7YuLi4qVapUlrnYAAAAAICHS2pqqiRlyd/y58+vtLS0O+67ePFiNW3aVFWrVrVr3717tzZt2qSJEyfKxSXrtchnz57V5cuXde3aNUVGRmrOnDkqVqyYunXrpuPHj+c49lxXbM1ms06cOKHLly9nuz00NFSurq7asWNHbocAAAAAgIeekfexvZeK7N14eHhIupnrZf5bujmV2NPT87b7nTlzRnFxcZo/f75de1JSkkaNGqVx48apRIkS2e5bsmRJxcfHy9PTUyaTSZJUs2ZNHT58WMuXL9f48eNzFHuuEttvvvlGgwcP1l9//ZVlm9VqlYuLi44cOXLPx01NTdXWrVuVmJioxx57TE2aNMk2qwcAAAAA3F+ZU5DPnz+vcuXK2drPnz+fZTGoW23btk2+vr5q2LChXfuuXbt04cIFjRo1SqNGjZJ0M2m2WCwKCQnR5s2bVapUKRUsWNBuP1dXV1WuXFmJiYk5jj1Xie3EiRPl6+urcePGqXDhwrk5hK5cuaKRI0dqz549aty4sUaNGqXu3bvr9OnTKly4sP766y8FBwfro48+kre3d67GAAAAAIC89k+53U9gYKC8vb0VFxdnS2xTUlJ0+PBhdevW7bb77du3T/Xq1ZObm316+cwzz6h27dp2bTExMTp37pxiYmJUvHhx7d69WwMGDNDGjRtVtmxZSVJ6erqOHj2qli1b5jj2XCW2v//+u+bMmZMlI78X06ZN06+//qqBAwdqw4YN6tq1q4oWLaqPP/5YxYsX1++//64BAwZoypQpio6OzvU4AAAAAIC7c3d3V7du3RQTEyNfX1+VLl1a06ZNk7+/v1q2bKmMjAwlJSXJx8fHbqry4cOH1aFDhyzH8/b2zlKk9PLykoeHh8qXLy9Jql27tooUKaLhw4dr1KhRMplMmj9/vpKTk7O9F+7t5GrxqICAAJ09ezY3u9p89dVXevfdd9WjRw9NmzZNf/zxh4YNG6bixYtLksqVK6fRo0frq6++cmgcAAAAAMhL/5Tb/UhSRESEOnbsqMjISL388svKly+fFi5cKJPJpLNnz6pRo0basmWL3T4XLlzI9Uxeb29vLVmyRMWKFVPv3r31r3/9S8nJyVqxYoWKFSuW4+PkqmI7atQoDRkyRPny5VNQUFC2FxKXKlXqjse4fv26ihQpIkmqXLmyypcvn+U4hQsXlsViyU2IAAAAAIB7lC9fPg0dOlRDhw7Nsq1MmTJKSEjI0n7w4MEcH3/y5MlZ2sqVK6cPPvjg3gL9G4dWRc68ADg7d1s8KigoSB999JHGjx8vV1dXffnll3bbr1y5opiYmCxzsgEAAAAAuFWuEttx48bJzc1NgwYNuqfy8K2GDh2qXr166dq1a5o+fbrdtl27dikiIkJFihTR0qVLc3V8AAAAAHgQjLzdD27KVWJ74sQJffDBB2rSpEmuB65evbq2bNmiP/74I8u2cuXKadiwYWrTpo0KFSqU6zEAAAAAAP98uUpsy5cvr2vXrjk8eNGiRVW0aNEs7RUrVlTFihUdPj4AAAAA5LV/yu1+nFmuVkUeMGCAZsyYob179+rq1av3OyabtLQ0bdiwIc+ODwAAAABwfrmq2E6fPl0XL15Unz59st3u4uKiw4cPOxSYJF2+fFkjRozQiy++6PCxAAAAAAD/TLlKbFu3bn2/48iWr6+vtm/f/kDGAgAAAIDcYPEo4+UqsQ0PD78vg6enp2vr1q2Kj4/X2bNnZTab5enpqRIlSig0NFQtW7ZU6dKl78tYAAAAAIB/plzfxzYtLU0JCQkym82yWq2SJIvFotTUVO3bt09Dhgy54/6nT59W7969lZiYqGrVqql48eIqVKiQ0tLSdPToUX366aeKjY3VRx99pFKlSuU2TAAAAADIU1ajA0DuEtu4uDgNGDBAly5dyna7l5fXXRPbqKgolSlTRuvWrZOPj0+W7SkpKRo4cKCioqI0d+7c3IQJAAAAAHgE5CqxnTFjhooUKaLo6Ght3LhRrq6uCgsL0+7du7Vq1SotWLDgrseIj4/X6tWrs01qJalgwYIaOnSounbtmpsQAQAAAOCB4Bpb4+Xqdj8JCQkKDw/XM888o6ZNm+rs2bN6+umn9c4776hjx4768MMP73oMHx8fJSYm3rHPmTNn5OHhkZsQAQAAAACPiFwlthaLRSVKlJAklS9fXj///LNt27PPPpujW/107NhRI0aM0Jo1a3Ty5EmZzWZJktls1qlTp7R+/XqNHj1aYWFhuQkRAAAAAPCIyNVU5HLlyikhIUF169ZVxYoVlZqaqhMnTqhSpUpKT0/X1atX73qM/v37y9XVVVOnTtW1a9eybPfy8lLXrl01YMCA3IQIAAAAAA+ElanIhstVYtu2bVvFxMTIarWqW7duqlGjhqKjo9W9e3fNnTtXVapUuesxXFxcFB4err59++rIkSNKTExUamqqPDw85O/vr8DAQLm7u+cmPAAAAADAIyRXiW2fPn30119/6eDBg+rWrZvGjh2r1157TW+++aa8vb1zdI1tJpPJpKCgoNyEAQAAAACGsxgdAHKX2P76668aPny47XnNmjW1bds223Rkb2/v+xYgAAAAAAB3kqvFo7p06aINGzbYtXl7eysoKIikFgAAAADwQOWqYmsymVSkSJH7HQsAAAAAOB2rWDzKaLlKbAcMGKCpU6fq8uXLCgwMVIECBbL0KVWqlMPBAQAAAABwN7lKbMeNG6eMjAwNHTr0tn2OHDmS66AAAAAAwFlYrEZHgFwltu++++79jgMAAAAAgFzJVWLbvn37+x0HAAAAADglC9fYGi5Xia0kJSYmav/+/TKbzbY2i8Wi1NRU7du3TzNmzLgvAQIAAAAAcCe5Smz/85//aMiQIUpPT5eLy82/TlitVtu/K1WqdP8iBAAAAADgDnJ1H9u5c+eqevXq+vTTTxUWFqZ27dpp8+bNGjp0qPLly6dRo0bd7zgBAAAA4KFklYthD9yUq4rtr7/+qunTp6tatWp64okntGjRIlWuXFmVK1fWxYsXNXfuXDVs2PB+xwoAAAAAQBa5qti6urqqUKFCkqTy5cvrxIkTslgskqSnnnpKx48fv38RAgAAAMBDzGLgAzflKrGtVKmSvv/+e9u/zWazjh49KklKSUmxW1AKAAAAAIC8lKupyJ07d9bYsWN17do1DRw4UPXr19fIkSPVsWNHrVixQtWrV7/fcQIAAAAAkK1cVWw7deqk0aNH2yqz0dHRMpvNmjBhgtLT0zV69Oj7GiQAAAAAPKxYPMp4ub6PbdeuXbVnzx7NmDFDycnJev755/X444/rueeeu5/xAQAAAABwR7lKbC9duqS+ffvq4MGDypcvnwoXLqzk5GRlZGTos88+U2xsrNzd3e93rAAAAADw0GERJ+PlairyxIkT9euvvyo2NlaHDh3Snj179OOPP2rmzJn64YcfNGPGjPsdJwAAAAAA2cpVYvv1119ryJAhatGihVxcbs7rdnV1VcuWLTVw4EBt2rTpvgYJAAAAAA8rbvdjvFwltlarVcWKFct2W8mSJXXt2jWHggIAAAAAIKdyldi2b99eH374oa5evWrXnp6erhUrVqh9+/b3JTgAAAAAAO4mV4tHeXp66rffflPz5s3VvHlzlShRQn/99Zd27dqlc+fOqVChQho5cqQkycXFRRMnTryvQQMAAADAw4Lb7hgvV4ntxo0b5e3tLUn65ptv7Lb5+/vr+++/tz3PvAYXAAAAAIC8kKvEdseOHfc7DgAAAABwShZqeYbL1TW2AAAAAAA8LEhsAQAAAABOLVdTkQEAAAAAN1lYPMpwVGwBAAAAAE6Nii0AAAAAOMBqdACgYgsAAAAAcG5UbAEAAADAARajA8CjndgWyl/A6BCAPOdSqITRIQB5zrPQDaNDAPKci8nT6BAA4KHFVGQAAAAAgFN7pCu2AAAAAOAoiwu3+zEaFVsAAAAAgFOjYgsAAAAADuB2P8ajYgsAAAAAcGoktgAAAAAAp8ZUZAAAAABwAPexNR4VWwAAAACAU6NiCwAAAAAOsHC3H8NRsQUAAAAAODUSWwAAAACAU2MqMgAAAAA4wCLmIhuNii0AAAAAwKlRsQUAAAAAB1iNDgBUbAEAAAAAzo2KLQAAAAA4gNv9GI+KLQAAAADAqZHYAgAAAACcGlORAQAAAMABFqMDABVbAAAAAIBzo2ILAAAAAA7gdj/Go2ILAAAAAHBqJLYAAAAAAKfGVGQAAAAAcAD3sTUeFVsAAAAAgFMjsQUAAAAAB1gMfNz312Kx6IMPPlDjxo0VHBys1157TadOncq2b2xsrAICArJ9jBw5Mkt/q9Wq3r17q3v37nbtaWlpGj9+vBo0aKCQkBANHjxYSUlJ9xQ3iS0AAAAAQJI0Z84crVy5UtHR0Vq9erUsFov69Okjs9mcpW+vXr20Z88eu0fv3r1VoEAB9ezZM0v/pUuXas+ePVnax40bpz179ig2NlZLly7ViRMnFBERcU9xk9gCAAAAgAP+KRVbs9msRYsWKSIiQk2aNFFgYKBmzJihc+fOaevWrVn6e3l5yc/Pz/a4cOGCli1bpjFjxiggIMCub0JCgmbPnq3g4GC79sTERG3YsEGRkZGqW7eugoKC9N577yk+Pl4HDhzIcewktgAAAAAAHT16VFevXlWDBg1sbQULFlS1atUUHx9/1/2joqJUt25dtW/f3q49LS1NQ4YMUUREhCpWrGi3bf/+/ZKk+vXr29oqVqyoEiVK5GjMTKyKDAAAAABOqnnz5nfcvn379hwf69y5c5KkkiVL2rUXL17ctu12du7cqQMHDmjDhg1Ztk2bNk3FixdXt27dslx7m5iYqCJFiih//vz3POatSGwBAAAAwAHWf8jtflJTUyVJ7u7udu358+fXpUuX7rjv4sWL1bRpU1WtWtWufffu3dq0aZM2btwoF5esb1RqamqW8TLHTEtLy3HsJLYAAAAA4KTupSJ7Nx4eHpJuXmub+W/p5lRiT0/P2+535swZxcXFaf78+XbtSUlJGjVqlMaNG6cSJUrcdszsFqa625h/R2ILAAAAAA7Ii9vuGCFzCvL58+dVrlw5W/v58+ezLAZ1q23btsnX11cNGza0a9+1a5cuXLigUaNGadSoUZJuJs0Wi0UhISHavHmz/P39lZycLLPZbFe5PX/+/G2T4eyQ2AIAAAAAFBgYKG9vb8XFxdkS25SUFB0+fFjdunW77X779u1TvXr15OZmn14+88wzql27tl1bTEyMzp07p5iYGBUvXlx16tSRxWLR/v37bYtW/frrr0pMTFRoaGiOYyexBQAAAADI3d1d3bp1U0xMjHx9fVW6dGlNmzZN/v7+atmypTIyMpSUlCQfHx+7qcqHDx9Whw4dshzP29tb3t7edm1eXl7y8PBQ+fLlJUklSpRQ69atFRkZqYkTJ8rT01Njx45VvXr1stwa6E4MS2zPnDmjkiVL2l1AnJSUpE8//VTnzp3T448/rhdffDHbC4kBAAAA4GHxT5mKLEkRERFKT09XZGSkrl+/rtDQUC1cuFAmk0mnT59W8+bNNWnSJIWFhdn2uXDhggoXLpzrMaOjozVx4kSFh4dLkp566ilFRkbe0zFcrFarNdcROKBq1aras2ePihYtKkn67bff1KVLF1ksFpUpU0a//fabihYtqmXLlt3T3Op7UbpI9Tw5LvAwORE3z+gQgDx38ZUxRocA5Lli84YbHQKQ5/IHPWt0CLkyq+ztp+nmtfBTKwwb+2HiatTAf8+np02bpmrVqunrr7/WunXr9PXXX6tUqVKaPHmyQRECAAAAwN1ZDXzgJsMS27/78ccf1a9fP9tcbW9vbw0aNEh79uwxODIAAAAAwMPMsGtsXVxc7K6vLVy4cJb7FHl6emZ7E18AAAAAeFhYSFkMZ1hia7VaNXDgQAUEBKhy5coKCAjQokWLFBMTI0m6fv26PvjgA9WsWdOoEAEAAAAATsCwxHbatGlKSEjQsWPH9OWXXyoxMVEuLi6KjIxU4cKF9fTTT0uSlixZYlSIAAAAAAAnYFhi27ZtW7Vt29b2PCUlRceOHbMtEz148GA99dRT8vf3NyhCAAAAALi7f9LtfpyVYYnt3xUsWFB169a1PX/ppZcMjAYAAAAA4CwemlWRs5OWlqYNGzYYHQYAAAAA3JbFwAdueqgT28uXL2vEiBFGhwEAAAAAeIg91Imtr6+vtm/fbnQYAAAAAICHmKHX2Kanp2vr1q2Kj4/X2bNnZTab5enpqRIlSig0NFQtW7ZU6dKljQwRAAAAAO7IanQAMK5ie/r0abVu3VqjRo1SQkKCPDw85OfnJ5PJpKNHj2rkyJFq27atzpw5Y1SIAAAAAAAnYFjFNioqSmXKlNG6devk4+OTZXtKSooGDhyoqKgozZ0714AIAQAAAODuLC5GRwDDKrbx8fEaNmxYtkmtdPP2P0OHDlV8fPwDjgwAAAAA4EwMS2x9fHyUmJh4xz5nzpyRh4fHA4oIAAAAAO4dt/sxnmGJbceOHTVixAitWbNGJ0+elNlsliSZzWadOnVK69ev1+jRoxUWFmZUiAAAAAAAJ2DYNbb9+/eXq6urpk6dqmvXrmXZ7uXlpa5du2rAgAEGRAcAAAAAcBaGJbYuLi4KDw9X3759deTIESUmJio1NVUeHh7y9/dXYGCg3N3djQoPAAAAAHKE2/0Yz9D72EqSyWRSUFCQ0WEAAAAAAJyU4YktAAAAADgzCzVbwxm2eBQAAAAAAPcDiS0AAAAAwKkxFRkAAAAAHMD9ZI1HxRYAAAAA4NSo2AIAAACAA1g6ynhUbAEAAAAATo2KLQAAAAA4gGtsjUfFFgAAAADg1EhsAQAAAABOjanIAAAAAOAAi4vREYCKLQAAAADAqVGxBQAAAAAHWLjhj+Go2AIAAAAAnBqJLQAAAADAqTEVGQAAAAAcwERk41GxBQAAAAA4NSq2AAAAAOAAi9EBgIotAAAAAMC5UbEFAAAAAAdwux/jUbEFAAAAADg1ElsAAAAAgFNjKjIAAAAAOICJyMajYgsAAAAAcGpUbAEAAADAAdzux3hUbAEAAAAATo3EFgAAAADg1JiKDAAAAAAO4D62xqNiCwAAAABwalRsAQAAAMAB1GuNR8UWAAAAAODUHumK7cXUFKNDAPKc5bcfjQ4ByHMpFz2MDgHIc75nfzY6BCDvBT1rdARwUo90YgsAAAAAjuI+tsZjKjIAAAAAwKlRsQUAAAAAB1hZPspwVGwBAAAAAE6Nii0AAAAAOIBrbI1HxRYAAAAA4NRIbAEAAAAATo2pyAAAAADgAAuLRxmOii0AAAAAwKlRsQUAAAAAB1CvNR4VWwAAAACAUyOxBQAAAAA4NaYiAwAAAIADWDzKeFRsAQAAAABOjYotAAAAADjAYnQAoGILAAAAAHBuVGwBAAAAwAFWrrE1HBVbAAAAAIBTI7EFAAAAADg1piIDAAAAgANYPMp4VGwBAAAAAE6Nii0AAAAAOIDFo4xHxRYAAAAAIEmyWCz64IMP1LhxYwUHB+u1117TqVOnsu0bGxurgICAbB8jR4609Vu+fLlatmypmjVrqnXr1lq/fr3dcfbv35/tMeLi4nIcNxVbAAAAAIAkac6cOVq5cqUmT54sf39/TZs2TX369NGmTZvk7u5u17dXr17q3LmzXdvixYu1atUq9ezZU5K0Zs0axcTE6N1331VwcLC++eYbvfPOOypUqJBatGghSUpISFC5cuW0cuVKu2MVKlQox3GT2AIAAACAA/4pi0eZzWYtWrRIQ4YMUZMmTSRJM2bMUOPGjbV161a1adPGrr+Xl5e8vLxszw8fPqxly5YpOjpaAQEBkqTLly9r8ODBatu2rSSpbNmyWrlypfbu3WtLbI8dO6YqVarIz88v17EzFRkAAAAAoKNHj+rq1atq0KCBra1gwYKqVq2a4uPj77p/VFSU6tatq/bt29va+vTpox49ekiSbty4oS1btuiXX35Rw4YNbX0SEhJUuXJlh2KnYgsAAAAADrBY/xmLR507d06SVLJkSbv24sWL27bdzs6dO3XgwAFt2LAh2+379u1T9+7dZbFY1KFDBzVv3ty27eeff1aRIkUUFhamxMREPf744xo4cKCCgoJyHDuJLQAAAAA4qVsTxOxs3749x8dKTU2VpCzX0ubPn1+XLl26476LFy9W06ZNVbVq1Wy3V6xYUZ999pkOHTqkiRMnqkiRIho6dKjOnj2ry5cv69q1a4qMjFS+fPm0YsUKdevWTZ9++qmqVKmSo9hJbAEAAADAAf+Meq3k4eEh6ea1tpn/lqS0tDR5enredr8zZ84oLi5O8+fPv22fokWLqmjRogoMDFRSUpJmzZqlAQMGqGTJkoqPj5enp6dMJpMkqWbNmjp8+LCWL1+u8ePH5yh2ElsAAAAAcFL3UpG9m8wpyOfPn1e5cuVs7efPn7ctBpWdbdu2ydfX1+662Uy7d+9WqVKl7CqvAQEBMpvNSk5OVvHixVWwYEG7fVxdXVW5cmUlJibmOHYWjwIAAAAAKDAwUN7e3nb3j01JSdHhw4cVGhp62/327dunevXqyc0ta930/fff15w5c+zaDh48qMKFC6tYsWLavXu3QkJC7O6Vm56erqNHj+Z4GrJExRYAAAAAHGL5h0xGdnd3V7du3RQTEyNfX1+VLl1a06ZNk7+/v1q2bKmMjAwlJSXJx8fHbqry4cOH1aFDh2yP2adPHw0aNEi1a9dW48aNFRcXp4ULF2rYsGFydXVV7dq1VaRIEQ0fPlyjRo2SyWTS/PnzlZycbLsXbk6Q2AIAAAAAJEkRERFKT09XZGSkrl+/rtDQUC1cuFAmk0mnT59W8+bNNWnSJIWFhdn2uXDhggoXLpzt8Vq1aqUbN25owYIFmjJlikqVKqV33nlHnTp1kiR5e3tryZIliomJUe/evZWWlqY6depoxYoVKlasWI7jdrFa/yFrU+dCfo+yRocA5LnkjSONDgHIc7+99W+jQwDyXIVZrYwOAchzns+GGx1Crrxc/kXDxl51coNhYz9MuMYWAAAAAODUDEtsR48erePHjxs1PAAAAADgH8KwxHb9+vX617/+pc8//9yoEAAAAADAYRYDH7jJ0KnInTt31ujRo9W7d28lJCQYGQoAAAAAwEkZmtj26tVLn3zyia5evaoXX3xRb775pvbs2SOLhb89AAAAAHAOFlkNe+Amw2/3U61aNa1evVo7d+7UkiVL1KdPHxUtWlT16tVTYGCgihQpopdeesnoMAEAAAAADynDElsXFxe7502bNlXTpk119uxZffXVV9q3b5/WrVunixcvktgCAAAAeGhZqZwazrDE9na3zy1ZsqR69OihHj16POCIAAAAAADOyLBrbMPDw1WgQAGjhgcAAAAA/EMYVrENDw83amgAAAAAuG9Y+tZ4hq6KfDdpaWnasGGD0WEAAAAAAB5iD3Vie/nyZY0YMcLoMAAAAADgtqxWq2EP3PRQJ7a+vr7avn270WEAAAAAAB5iht7HNj09XVu3blV8fLzOnj0rs9ksT09PlShRQqGhoWrZsqVKly5tZIgAAAAAgIecYRXb06dPq3Xr1ho1apQSEhLk4eEhPz8/mUwmHT16VCNHjlTbtm115swZo0IEAAAAgLuyyGrYAzcZVrGNiopSmTJltG7dOvn4+GTZnpKSooEDByoqKkpz5841IEIAAAAAgDMwLLGNj4/X6tWrs01qJalgwYIaOnSounbt+oAjAwAAAICc43Y/xjNsKrKPj48SExPv2OfMmTPy8PB4QBEBAAAAAJyRYYltx44dNWLECK1Zs0YnT56U2WyWJJnNZp06dUrr16/X6NGjFRYWZlSIAAAAAHBXVgP/w02GTUXu37+/XF1dNXXqVF27di3Ldi8vL3Xt2lUDBgwwIDoAAAAAgLMwLLF1cXFReHi4+vbtqyNHjigxMVGpqany8PCQv7+/AgMD5e7ublR4AAAAAAAnYeh9bCXJZDIpKCjI6DAAAAAAIFe47Y7xDLvGFgAAAACA+8Hwii0AAAAAODOrlYqt0ajYAgAAAACcGoktAAAAAMCpMRUZAAAAABxgMToAULEFAAAAADg3KrYAAAAA4AArt/sxHBVbAAAAAIBTo2ILAAAAAA6wULE1HBVbAAAAAIBTI7EFAAAAADg1piIDAAAAgAOsVqYiG42KLQAAAADAqVGxBQAAAAAHsHiU8ajYAgAAAACcGoktAAAAAMCpMRUZAAAAABxgZSqy4ajYAgAAAACcGhVbAAAAAHCAhdv9GI6KLQAAAADAqZHYAgAAAACcGlORAQAAAMABTEQ2HhVbAAAAAIBTo2ILAAAAAA6wULM1HBVbAAAAAIBTo2ILAAAAAA6gYms8KrYAAAAAAKdGYgsAAAAAcGpMRQYAAAAAB1itTEU2GhVbAAAAAIBTo2ILAAAAAA5g8SjjPdKJbYbFYnQIQJ6zJvxkdAhAnku9bjI6BCDPWX/Yb3QIQN571ugA4KyYigwAAAAAcGqPdMUWAAAAABxlZSqy4ajYAgAAAACcGhVbAAAAAHAAt/sxHhVbAAAAAIBTo2ILAAAAAA7gdj/Go2ILAAAAAHBqJLYAAAAAAKfGVGQAAAAAcACLRxmPii0AAAAAwKlRsQUAAAAAB7B4lPGo2AIAAAAAnBqJLQAAAADAqTEVGQAAAAAcYGUqsuGo2AIAAAAAnBoVWwAAAABwgIXb/RiOii0AAAAAwKlRsQUAAAAAB3CNrfGo2AIAAAAAnBqJLQAAAABAkmSxWPTBBx+ocePGCg4O1muvvaZTp05l2zc2NlYBAQHZPkaOHGnrt3z5crVs2VI1a9ZU69attX79ervjpKWlafz48WrQoIFCQkI0ePBgJSUl3VPcJLYAAAAA4ACL1WrY436bM2eOVq5cqejoaK1evVoWi0V9+vSR2WzO0rdXr17as2eP3aN3794qUKCAevbsKUlas2aNYmJi1L9/f23ZskWvvPKK3nnnHW3bts12nHHjxmnPnj2KjY3V0qVLdeLECUVERNxT3CS2AAAAAACZzWYtWrRIERERatKkiQIDAzVjxgydO3dOW7duzdLfy8tLfn5+tseFCxe0bNkyjRkzRgEBAZKky5cva/DgwWrbtq3Kli2rl156SY8//rj27t0rSUpMTNSGDRsUGRmpunXrKigoSO+9957i4+N14MCBHMdOYgsAAAAADrAa+N/9dPToUV29elUNGjSwtRUsWFDVqlVTfHz8XfePiopS3bp11b59e1tbnz591KNHD0nSjRs3tGXLFv3yyy9q2LChJGn//v2SpPr169v2qVixokqUKJGjMTOxKjIAAAAAQOfOnZMklSxZ0q69ePHitm23s3PnTh04cEAbNmzIdvu+ffvUvXt3WSwWdejQQc2bN5d0s2JbpEgR5c+f/57HvBWJLQAAAAA4qcwE8Xa2b9+e42OlpqZKktzd3e3a8+fPr0uXLt1x38WLF6tp06aqWrVqttsrVqyozz77TIcOHdLEiRNVpEgRDR06VKmpqVnGyxwzLS0tx7GT2AIAAACAA/JiEScjeHh4SLp5rW3mv6WbqxZ7enredr8zZ84oLi5O8+fPv22fokWLqmjRogoMDFRSUpJmzZqlAQMGyMPDI9uFqe425t+R2AIAAACAk7qXiuzdZE5BPn/+vMqVK2drP3/+vG0xqOxs27ZNvr6+tutmb7V7926VKlVKVapUsbUFBATIbDYrOTlZ/v7+Sk5Oltlstqvcnj9/XiVKlMhx7CweBQAAAAAO+KcsHhUYGChvb2/FxcXZ2lJSUnT48GGFhobedr99+/apXr16cnPLWjd9//33NWfOHLu2gwcPqnDhwipWrJjq1Kkji8ViW0RKkn799VclJibeccy/I7EFAAAAAMjd3V3dunVTTEyMtm/frqNHj2rgwIHy9/dXy5YtlZGRoQsXLuj69et2+x0+fFiBgYHZHrNPnz7asmWLVqxYoZMnT+qTTz7RwoUL1b9/f7m6uqpEiRJq3bq1IiMjFRcXpx9//FGDBg1SvXr1FBwcnOPYmYoMAAAAAA74p1xjK0kRERFKT09XZGSkrl+/rtDQUC1cuFAmk0mnT59W8+bNNWnSJIWFhdn2uXDhggoXLpzt8Vq1aqUbN25owYIFmjJlikqVKqV33nlHnTp1svWJjo7WxIkTFR4eLkl66qmnFBkZeU9xu1it/6Cfwj1ycy9tdAhAnkuZ3s7oEIA8d3TqH0aHAOS5wHBfo0MA8lyB4YuNDiFXKherbdjYv1z83rCxHyZMRQYAAAAAODWmIgMAAACAA+73Ik64d1RsAQAAAABOjYotAAAAADjAarUYHcIjz/DE9syZM4qPj1dSUpJu3Lghb29vlStXTiEhIfLy8jI6PAAAAADAQ86wxDYjI0NjxozR+vXr/18wbm4qUqSILl68KE9PT73xxht6/fXXjQoRAAAAAOAEDEts58yZowMHDmjlypWqVq2aTp8+rQkTJqhp06bq1KmTvvzyS02YMEGenp7q3r27UWECAAAAwB1ZWDzKcIYtHrV+/Xq9++67ql27tjw8PFSlShVNmzZNsbGxMplMevHFFzVp0iQtX77cqBABAAAAAE7AsIrt1atXVaBAAbs2Ly8vXb16VcnJySpWrJgCAwN14cIFgyIEAAAAgLuzWqnYGs2wim1ISIgmTZqkS5cuSbp5Mrz33nsqVqyYihUrJovFouXLlysgIMCoEAEAAAAATsCwiu3o0aPVpUsXNW3aVJUrV9b58+eVnJysmTNnSpJ69uyphIQEzZs3z6gQAQAAAOCuuMbWeIYltuXLl9cXX3yhTz/9VL///ruKFy+u559/XuXLl5ckDRgwQJUqVVKRIkWMChEAAAAA4AQMvY9twYIF1bNnz2y31alT58EGAwAAAABwSoZdY5sTaWlp2rBhg9FhAAAAAMBtWa1Wwx646aFObC9fvqwRI0YYHQYAAAAA4CFm6FTku/H19dX27duNDgMAAAAAbstC5dRwhia26enp2rp1q+Lj43X27FmZzWZ5enqqRIkSCg0NVcuWLVW6dGkjQwQAAAAAPOQMm4p8+vRptW7dWqNGjVJCQoI8PDzk5+cnk8mko0ePauTIkWrbtq3OnDljVIgAAAAAACdgWMU2KipKZcqU0bp16+Tj45Nle0pKigYOHKioqCjNnTvXgAgBAAAA4O6s3MfWcIZVbOPj4zVs2LBsk1rp5q2Ahg4dqvj4+AccGQAAAADAmRiW2Pr4+CgxMfGOfc6cOSMPD48HFBEAAAAA3Dtu92M8wxLbjh07asSIEVqzZo1Onjwps9ksSTKbzTp16pTWr1+v0aNHKywszKgQAQAAAABOwLBrbPv37y9XV1dNnTpV165dy7Ldy8tLXbt21YABAwyIDgAAAAByxsI1toYzLLF1cXFReHi4+vbtqyNHjigxMVGpqany8PCQv7+/AgMD5e7ublR4AAAAAAAnYeh9bCXJZDIpKCjI6DAAAAAAAE7K8MQWAAAAAJwZizgZz7DFowAAAAAAuB+o2AIAAACAAyxUbA1HxRYAAAAA4NRIbAEAAAAATo2pyAAAAADgABaPMh4VWwAAAACAU6NiCwAAAAAOsIiKrdGo2AIAAAAAnBqJLQAAAADAqTEVGQAAAAAcwOJRxqNiCwAAAABwalRsAQAAAMABFiq2hqNiCwAAAABwalRsAQAAAMABVm73YzgqtgAAAAAAp0ZiCwAAAABwakxFBgAAAAAHsHiU8ajYAgAAAACcGhVbAAAAAHCAlYqt4ajYAgAAAACcGoktAAAAAMCpMRUZAAAAABzAfWyNR8UWAAAAAODUqNgCAAAAgANYPMp4VGwBAAAAAE6Nii0AAAAAOICKrfGo2AIAAAAAnBqJLQAAAADAqTEVGQAAAAAcwERk41GxBQAAAAA4NRcrVzoDAAAAAJwYFVsAAAAAgFMjsQUAAAAAODUSWwAAAACAUyOxBQAAAAA4NRJbAAAAAIBTI7EFAAAAADg1ElsAAAAAgFMjsQUAAAAAODUSWwAAAACAUyOxBQAAAAA4NRJbAAAAAIBTI7EFAAAAADg1ElsAAAAAgFMjsQUAAAAAODUSWwAAAACAUyOxBQAAAAA4NRJbAAAAAIBTI7HFPQsICNCnn34qSYqNjVWzZs3u2P/QoUN6/vnnVaNGDU2ZMuVBhAhk63bn7unTpxUQEKC4uLjb7jtixAh17949x/0BAADw4LgZHQD++ebNmyeTyaQtW7bIx8fH6HAASVKvXr3UtWvXXO1bsmRJ7dmzR4UKFbrPUQEAACA3SGyR5y5duqSqVauqXLlyRocC2Hh5ecnLyytX++bLl09+fn73OSIAAADkFlORcV/Mnj1bTzzxhGrXrq0hQ4YoOTlZktSsWTN999132rBhgwICAnT69GllZGRoxowZatSokYKDgxUREaEJEybYpnlK0sKFC9WiRQvVqFFDzZo10+zZs2W1Wg16dfgnym4a/YEDB9S2bVvVqFFDYWFh+vbbb7Pd9+9Tkbt3766YmBiNGjVKdevWVe3atTV48GBduXLFts8vv/yi1157TSEhIWrUqJEGDx6sCxcu2LZfunRJkZGRaty4sapXr64GDRooMjJSqampkqS4uDhVq1ZN8+fP1xNPPKGwsDBZLJb7/bbgEbdr1y6FhYWpVq1aatCggUaMGKFLly5JkrZt26ZOnTopODhYNWvWVFhYmP773//a9s3JZztghLw+r+92DAAPBoktHPbHH3/o22+/1eLFizV37lwdOnRII0eOlCStW7dOISEhev7557Vnzx6VLFlSMTExWrNmjcaOHav169fLz89Py5cvtx1vx44dmjdvnsaPH6+tW7dqyJAh+vDDD7Vx40ajXiIeEQsXLlS/fv30+eefq1q1aurbt68SExNztO+SJUtUrFgxrVu3TtOmTdP27du1ZMkSSVJiYqK6dOmi8uXLa926dZo7d66uXLmif/3rX7p27Zqkm9fwHj58WLNmzdKXX36pkSNHasOGDVqzZo1tjIyMDO3atUtr1qzRhAkT5OrKRzjun6SkJIWHh6tDhw7asmWLZs2apfj4eE2dOlU//fST+vfvr9atW2vTpk365JNP5Ovrq2HDhslsNkvSXT/bASPk9Xmdk2MAeDCYigyH5c+fXzNmzFCxYsUkSWPGjFGvXr108uRJlS9fXiaTSR4eHvLz81NqaqpWrlypkSNH6plnnpEkRUZG6sCBA7bj/f7773J3d1fp0qVVqlQplSpVSsWLF1epUqUMeX14dPTv31+tWrWSJI0bN07/93//p5UrV2rgwIF33bdKlSoaNGiQJKlChQpq2LCh7bxetWqV/P39FRkZaev//vvvq379+vrPf/6jsLAwNWzYUKGhoQoICJAklSlTRitWrNCxY8fsxunVq5cqVKhwP14uYCcxMVFms1mlSpVS6dKlVbp0ac2dO1cZGRmyWq1655131KVLF1v/Hj166LXXXtOff/6pwoUL3/WzHTBCXp/X+fLlu+MxSpYs+eBeLPCII7GFw8qXL29LaiWpVq1akqSff/5Z5cuXt+v7yy+/6Pr16woODra1ubi4qE6dOjp69Kgk6YUXXtD69ev17LPPqkqVKnryySf17LPPktgiz9WpU8f2bzc3N1WrVk0///xzjvatVKmS3XMfHx+lpKRIkg4fPqyff/5ZISEhdn3S0tL0yy+/SJK6dOmiHTt26LPPPtNvv/2m48eP6/Tp01mOS1KLvFK1alW1adNGb7zxhvz8/NSwYUM1adJEzzzzjNzc3FSoUCHNnz9fJ06c0MmTJ22f2RkZGTn6bAeMkNfnddWqVe94DAAPDoktHJYvXz6755kf5CaTKUtfN7ebp9ydrpf19fXV559/rgMHDmjv3r3as2ePli1bpv79+ys8PPw+Rg7Yy+5czp8/f472dXd3v+02i8Wi+vXra+zYsVm2+fj4yGKxqG/fvvr555/Vpk0btWrVStWrV9c777yTpX9O4wFyY/r06Xrrrbe0e/du/d///Z+GDh2qOnXq6K233lLv3r3VpEkT1alTR23btlVqaqreeustSTn7bAeMkpfn9XfffXfHYwB4cEhs4bDffvtNV65ckbe3tyRp//79cnFxUZUqVbL0LV++vDw8PPTDDz+oatWqtvaDBw/avrBv3LhRly9fVteuXVWnTh1FREQoMjJSW7ZsIbFFnvrpp58UGBgoSTKbzfrpp5/UuXNnh4/72GOPacuWLSpZsqQtAU5OTtbw4cP16quvysfHR7t379Ynn3xim/Fw48YN/f777ypbtqzD4wM5cfDgQW3evFmjRo1SpUqV1LNnT23cuFFDhw6Vu7u7nnjiCcXGxtr6Z15naLVac/TZDhghr8/rRYsW3fEYAB4cEls4LC0tTW+//bYGDRqkv/76S9HR0XrxxRdVunTpLH09PT3VvXt3ffDBB/Lz81PlypX1ySef6ODBg6pXr57teFOmTJGXl5fq1q2rc+fOKT4+XnXr1n3QLw2PmOnTp6tw4cKqUKGC5syZI7PZnOt73d6qS5cuWrNmjYYMGaI333xTkjRlyhQlJCTo8ccf140bN+Tm5qYvvvhCvr6+Sk5O1ty5c3XhwgUWH8ED4+3trZUrV8pkMumll15SWlqatmzZogoVKqhUqVLasWOH9u3bJ39/f8XFxWnmzJmSbv4RKCef7YAR8vq8LlmypLZt23bbYwB4cEhs4bAaNWqoatWq6tGjh1xcXNSqVSuNGDHitv0HDBigGzdu2G5l0rRpUzVv3lxpaWmSpE6dOik5OVlz5szR2bNnVahQIT377LMaMmTIg3pJeET1799fMTExOn36tIKCgrR48WIVLlzY4eOWLVtWK1as0PTp0/Xyyy8rX758ql27tpYtWyZfX19J0uTJkxUbG6uPP/5Yfn5+atKkiXr27KkdO3Y4PD6QE5UrV1ZsbKxmzZqllStXytXVVfXr19eCBQvk4+OjpKQkvfHGG5JuLpY2ceJEDR06VIcOHVLlypXv+tkOGCGvz+uIiAhdvHjxjscA8GC4WJkngQfsq6++Up06dWxf6KWbK736+/tr4sSJBkYGAMgtPtvxT8R5DTgPboKIB27hwoUaPHiwjhw5olOnTmnJkiX69ttv9cILLxgdGgAgl/hsxz8R5zXgPKjY4oE7ffq0Jk+erPj4eF2/fl1VqlTRG2+8YbtHHADA+fDZjn8izmvAeZDYAgAAAACcGlORAQAAAABOjcQWAAAAAODUSGwBAAAAAE6NxBYAAAAA4NRIbAEAAAAATo3EFgCAO2jWrJlGjBhhdBgAAOAOSGwBAAAAAE6NxBYAAAAA4NRIbAHgEdasWTPNmDFDEydOVGhoqJ544gkNGzZMycnJtj5r165VWFiYgoODFRQUpHbt2umLL76wbf/0009VrVo1rV27Vg0bNlS9evV0/PhxZWRkaP78+WrTpo2CgoIUHByszp0769tvv7XtGxsbq+eee05fffWV2rRpo5o1a6pdu3Y6cOCAfvjhB3Xq1ElBQUFq06aNvvnmm3t+fUuXLtVzzz2nmjVrqnHjxho3bpyuXLli256WlqbZs2fb+rRs2VLz58+XxWLJ9njPPvusIiIisrS3a9dO/fr1sz3ftm2bwsLCVLNmTTVs2FDvvvuurl27Zve6n3nmGc2aNUv16tVTo0aNdOnSpXt+fQAA4CY3owMAABhr5cqVKl++vCZNmqSkpCRNnz5dJ0+e1OrVq7Vy5Uq9++676t+/v+rUqaNLly5pwYIFGjJkiEJCQuTv7y9JysjI0KJFizRhwgT99ddfqly5sqZOnapVq1Zp8ODBCggIUGJiombPnq0BAwbo66+/lqenpyTp3Llzmjx5sgYOHKgCBQooOjpaERERMplMeuONN1SyZEnb9q+//loeHh45el3//ve/NW3aNA0fPlwBAQE6ceKEpkyZotTUVE2ZMkVWq1VvvPGGfvjhB4WHhyswMFBxcXF6//33derUKUVHR2c55gsvvKD58+frypUr8vb2liT98ssvOnr0qC2x3bRpk4YMGaK2bdvq7bff1h9//KEZM2bo+PHjWrx4sVxcXCRJZ86c0a5duzRjxgwlJyerUKFCDv8sAQB4VJHYAsAjztXVVYsXL5aPj48kydfXV2+99Zb++9//6tSpU+rdu7fefPNNW//SpUsrLCxM+/fvV+vWrW3tb7zxhpo0aWJ7fv78eQ0cOFDdu3e3teXPn1/9+/dXQkKCgoODJUmpqakaO3asnnrqKUnS8ePHNX36dE2YMEEdO3aUJF27dk0RERH69ddfVbVq1Ry9ru+++05lypRR165d5erqqnr16qlAgQK2yuju3bv1f//3f3rvvfdsr6Nhw4by8PDQzJkz1aNHDz322GN2x3zhhRcUGxurbdu26cUXX5R0M4EuWLCgmjVrJqvVqpiYGDVu3FgxMTG2/SpUqKCePXtq165dtvcoPT1dw4cPV926dXP0egAAwO2R2ALAI65Zs2a2pDbzuZubm+Lj422rAaekpOjEiRM6efKk4uLiJElms9nuOH9POKdPny5JSkpKsu27c+fObPetXbu27d/FihWTJNWqVcvWVrhwYVscOVW/fn2tWbNGYWFhatGihZ5++mm1bdvWVjH97rvv5Obmpueee85uvxdeeEEzZ87Ud999lyWxLVu2rGrXrq0tW7bYEtvNmzfrueeek7u7u3755RedO3dOffv2VXp6um2/0NBQeXt7a+/evXbJf06TdAAAcGcktgDwiCtRooTdc1dXVxUpUkSXLl3S77//rjFjxuibb76RyWRSpUqVFBgYKEmyWq12+xUoUMDu+aFDhzR+/HgdOnRInp6eqlKlikqVKpXtvpnTem+VOVU5t1q1aiWLxaKVK1fq/2vvbkKi2sM4jn91jhFOM2ERBSbkMJQSbhKmWlQotNBEEQpaCYEFFZhGRosopJQKa1ExFbaIXhaBm4KggVz0sgrXgSBGYIgumtJ2zdBdxB3uaHUv92Yyd74fmMU5c54//2f545zznGQyybVr16isrOTEiRM0Nzfz6dMnKioqCIVCeXVr1qwBYG5u7rvrtrW1ce7cOdLpNJOTk7x7946BgQGA3LvJfX199PX1LaidmZnJOw6Hw/+pR0mS9I3BVpKKXDqdzjvOZrOk02lWrVrFoUOHKCsrY3h4mNraWoIgYHx8nEePHv10zc+fP9PZ2cmmTZt48uQJsViM0tJSnj9/TiqVWsx28rS0tNDS0sLc3ByvXr1iaGiI3t5e6uvrWblyJel0mmw2mxdu/wyfFRUV312zqamJ8+fP8+zZMyYmJqisrKS+vh6AaDQKwMmTJ0kkEgtqfY9WkqTF4VRkSSpyL168yHs0eGRkhEwmw8aNG3n79i179+6lrq6OIAhy1wM/nBwMMDExwcePH+no6CAej1NaWvqPa3+V7u5ujh49CkAkEqGpqYkjR46QyWSYmZkhkUiQyWR4+vRpXt3jx48BcmF1vmg0SkNDAyMjI6RSKVpbW3OPN8diMVavXs3k5CR1dXW539q1a7l8+TJv3rxZxI4lSSpe3rGVpCI3NTXF4cOH6ejoYGpqiitXrrBjxw6am5sZHBzkwYMHrFu3jmg0ysuXL7l79y7wbejTj1RXV7NixQpu3rxJEAQEQUAqlWJ4ePhva3+Vbdu2cfbsWS5evMjOnTuZnZ3l+vXrbNiwgZqaGoIgYOvWrZw+fZrp6Wlqamp4/fo1Q0NDtLe3E4/Hf7h2a2srXV1dZLNZ2tracudDoRA9PT2cOXOGUChEQ0MDs7OzJJNJpqen2bx586L3LUlSMTLYSlKR27NnD9FolO7ubsrLy2lvb6enpweAZDJJf38/p06dYtmyZcTjcW7cuMHAwACjo6N5E4//KhKJkEwmuXTpEseOHSMcDlNbW8v9+/c5ePAgo6OjNDY2Lmpf+/fv58uXL7nPFi1fvpzt27fT29tLWVkZALdu3eLq1avcuXOHDx8+sH79eo4fP86BAwd+uvauXbuIRCJUVVVRXV2d99++ffsIh8Pcvn2bhw8fUl5ezpYtWxgcHKSqqmrR+pUkqZiVfJ0/wUOSVDQaGxtJJBJcuHBhqbciSZL0r3nHVpJUULLZ7IKpyvOVlJQsmHYsSZL+vwy2kqSCsnv3bt6/f//TaxKJBPfu3ftNO5IkSUvNR5ElSQVlbGwsb4rz94TDYWKx2G/akSRJWmoGW0mSJElSQfM7tpIkSZKkgmawlSRJkiQVNIOtJEmSJKmgGWwlSZIkSQXNYCtJkiRJKmgGW0mSJElSQTPYSpIkSZIKmsFWkiRJklTQ/gAbOub+vfkaLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# отрисуем, как менялась точность при различных гиперпараметрах\n",
    "visual = pd.pivot_table(pd.DataFrame(grid_search.cv_results_),\n",
    "                        values='mean_test_score', index='param_C',\n",
    "                        columns='param_solver')\n",
    "sns.heatmap(visual)\n",
    "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
    "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.762      0.762             nan 0.742      0.76233333 0.762\n",
      "        nan 0.742      0.76233333 0.762             nan 0.742     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 311 ms, sys: 46.2 ms, total: 357 ms\n",
      "Wall time: 1min 39s\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'C': 0.127, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l2', 'none'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.125, 0.127, 0.128]}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  #количество фолдов кросс-валидации\n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью подбора сетки удалось увеличиль accuracy и f-score на 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/stevgenia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.95 s, sys: 66.9 ms, total: 4.01 s\n",
      "Wall time: 1min 54s\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'solver': 'sag', 'penalty': 'l2', 'C': 0.030000000000000006}\n"
     ]
    }
   ],
   "source": [
    "#np.linspace(start(от), stop(до), num=50(количество),dtype- тип данных)\n",
    "param_distributions = {'penalty': ['l2', 'none'] ,\n",
    "              'solver': ['lbfgs', 'sag'],\n",
    "               'C': list(np.linspace(0.01, 0.1, 10, dtype=float))},\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=1000), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5, \n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search.score(X_test, y_test)))\n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью подбора удалось увеличиль accuracy и f-score на 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.00\n",
      "Test: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики \n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По данным тренировочной выборки, видим признаки переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 684 ms, sys: 194 ms, total: 878 ms\n",
      "Wall time: 13.1 s\n",
      "accuracy на тестовом наборе: 0.73\n",
      "f1_score на тестовом наборе: 0.75\n",
      "Наилучшие значения гиперпараметров: {'min_samples_leaf': 10, 'max_depth': 3, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n",
    "              }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train_scaled, y_train) \n",
    "y_train_pred = random_search_forest.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения accuracy и f1_score уменьшились, но исчезли прищнаки переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 152 ms, total: 1.4 s\n",
      "Wall time: 19.6 s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения acuracy и f-score при выбранных параметрах выше, чем в случае RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'n_estimators': hp.quniform('n_estimators', 100, 300, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 40, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 3, 7, 1)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафксируем random_state\n",
    "random_state = int(42)\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.36s/trial, best loss: -0.9743433109346366]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 22.0, 'min_samples_leaf': 3.0, 'n_estimators': 201.0}\n",
      "CPU times: user 27 s, sys: 262 ms, total: 27.3 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.97\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.80\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения на тестовом наборе данных равны значениям, полученным при использование GridSearchCV, однако значение f1_score на обучающем наборе данных стало выше на 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 100, 300, 1)\n",
    "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 3, 7, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 19:53:47,310]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:49,151]\u001b[0m Trial 0 finished with value: 0.9457317073170731 and parameters: {'n_estimators': 248, 'max_depth': 36, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9457317073170731.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:50,582]\u001b[0m Trial 1 finished with value: 0.9224688355123138 and parameters: {'n_estimators': 214, 'max_depth': 31, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.9457317073170731.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:51,386]\u001b[0m Trial 2 finished with value: 0.9551418980775098 and parameters: {'n_estimators': 105, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.9551418980775098.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:52,238]\u001b[0m Trial 3 finished with value: 0.9205962884088835 and parameters: {'n_estimators': 125, 'max_depth': 40, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.9551418980775098.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:53,154]\u001b[0m Trial 4 finished with value: 0.9561510353227771 and parameters: {'n_estimators': 120, 'max_depth': 38, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9561510353227771.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:54,074]\u001b[0m Trial 5 finished with value: 0.9417860408412069 and parameters: {'n_estimators': 126, 'max_depth': 33, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9561510353227771.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:56,022]\u001b[0m Trial 6 finished with value: 0.9741248097412482 and parameters: {'n_estimators': 251, 'max_depth': 26, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:57,394]\u001b[0m Trial 7 finished with value: 0.9564422784038988 and parameters: {'n_estimators': 187, 'max_depth': 17, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:53:59,077]\u001b[0m Trial 8 finished with value: 0.9303316093702464 and parameters: {'n_estimators': 244, 'max_depth': 21, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:00,454]\u001b[0m Trial 9 finished with value: 0.9311395490554539 and parameters: {'n_estimators': 200, 'max_depth': 17, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:02,755]\u001b[0m Trial 10 finished with value: 0.9738124238733251 and parameters: {'n_estimators': 293, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:05,104]\u001b[0m Trial 11 finished with value: 0.9731870810481413 and parameters: {'n_estimators': 300, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:07,413]\u001b[0m Trial 12 finished with value: 0.9741248097412482 and parameters: {'n_estimators': 295, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:09,482]\u001b[0m Trial 13 finished with value: 0.9734513274336283 and parameters: {'n_estimators': 265, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9741248097412482.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:11,584]\u001b[0m Trial 14 finished with value: 0.97442143727162 and parameters: {'n_estimators': 271, 'max_depth': 31, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.97442143727162.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:13,280]\u001b[0m Trial 15 finished with value: 0.958904109589041 and parameters: {'n_estimators': 228, 'max_depth': 32, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.97442143727162.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:14,699]\u001b[0m Trial 16 finished with value: 0.9746874046965537 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:15,990]\u001b[0m Trial 17 finished with value: 0.9573690621193666 and parameters: {'n_estimators': 171, 'max_depth': 35, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:17,167]\u001b[0m Trial 18 finished with value: 0.9450884685784015 and parameters: {'n_estimators': 162, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 19:54:18,363]\u001b[0m Trial 19 finished with value: 0.9737484737484737 and parameters: {'n_estimators': 151, 'max_depth': 34, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.7 s, sys: 315 ms, total: 31.1 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 180, 'max_depth': 30, 'min_samples_leaf': 3}\n",
      "f1_score на обучающем наборе: 0.97\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.80\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 21:32:53,832]\u001b[0m Trial 20 finished with value: 0.9455098934550991 and parameters: {'n_estimators': 271, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:32:55,904]\u001b[0m Trial 21 finished with value: 0.9744058500914077 and parameters: {'n_estimators': 261, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:32:57,660]\u001b[0m Trial 22 finished with value: 0.9731543624161073 and parameters: {'n_estimators': 224, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:32:59,736]\u001b[0m Trial 23 finished with value: 0.9579780755176613 and parameters: {'n_estimators': 274, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:33:01,313]\u001b[0m Trial 24 finished with value: 0.9743589743589743 and parameters: {'n_estimators': 195, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:33:02,755]\u001b[0m Trial 25 finished with value: 0.9579268292682926 and parameters: {'n_estimators': 180, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:33:04,433]\u001b[0m Trial 26 finished with value: 0.9722137404580152 and parameters: {'n_estimators': 213, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:33:05,515]\u001b[0m Trial 27 finished with value: 0.9269628727936702 and parameters: {'n_estimators': 147, 'max_depth': 32, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:33:07,642]\u001b[0m Trial 28 finished with value: 0.9585870889159561 and parameters: {'n_estimators': 280, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 21:33:09,702]\u001b[0m Trial 29 finished with value: 0.9734675205855443 and parameters: {'n_estimators': 246, 'max_depth': 36, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9746874046965537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 193 ms, total: 17.9 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# можем прододжить подбор, указав n_trials(любое число, которое добавится к предыдущим итерациям) \n",
    "study.optimize(optuna_rf, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "f1_score",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.9457317073170731,
          0.9224688355123138,
          0.9551418980775098,
          0.9205962884088835,
          0.9561510353227771,
          0.9417860408412069,
          0.9741248097412482,
          0.9564422784038988,
          0.9303316093702464,
          0.9311395490554539,
          0.9738124238733251,
          0.9731870810481413,
          0.9741248097412482,
          0.9734513274336283,
          0.97442143727162,
          0.958904109589041,
          0.9746874046965537,
          0.9573690621193666,
          0.9450884685784015,
          0.9737484737484737,
          0.9455098934550991,
          0.9744058500914077,
          0.9731543624161073,
          0.9579780755176613,
          0.9743589743589743,
          0.9579268292682926,
          0.9722137404580152,
          0.9269628727936702,
          0.9585870889159561,
          0.9734675205855443
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.9457317073170731,
          0.9457317073170731,
          0.9551418980775098,
          0.9551418980775098,
          0.9561510353227771,
          0.9561510353227771,
          0.9741248097412482,
          0.9741248097412482,
          0.9741248097412482,
          0.9741248097412482,
          0.9741248097412482,
          0.9741248097412482,
          0.9741248097412482,
          0.9741248097412482,
          0.97442143727162,
          0.97442143727162,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537,
          0.9746874046965537
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "f1_score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: значения f_score и accuracy для HIPEROPT и OPTUNA равны, данные способы подбора гиперпараметров дают лучшие результаты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
